{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "389e430f-0675-4d1d-9388-d88f7b674ad3",
   "metadata": {},
   "source": [
    "<div class=\"infotext\" style='padding:0.1em; color:#000000'>\n",
    "<span>\n",
    "<p style='margin-top:1em; text-align:center'><font size=\"10\"><b>Spanish-to-Tarahumara Translation</b></font></p>\n",
    "    <p style='margin-top:1em; text-align:center'><font size=\"5\"><b>Bidirectional LSTM Encoder - Forward LSTM Decoder with Attention Layer</b></font></p>\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8caf8e32-c494-4d4f-aa56-5f8c51ff7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spanish-Tarahumara-Translator:  Bidirectional LSTM Encoder - Forward LSTM Decoder with Attention Layer\n",
    "# Copyright (C) 2022  Eduardo Aguilar Moreno\n",
    "\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb78928-1279-4495-b68c-fc2e04b8033a",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "926bc360-855a-4168-99a6-324276781193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e11bc49b-20c5-493f-b175-ad6b17970a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "62529de1-20a5-4e26-b484-0b227eb01437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e4ca75-b3f0-499f-b905-94f98281d0d9",
   "metadata": {},
   "source": [
    "# Viewing Sentence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c0896cb4-1f69-4452-82c5-5b688bcb95dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length in Spanish: 83\n",
      "Maximum length in Tarahumara: 103\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME = \"./corpora/rarámuri.txt\"\n",
    "#FILE_NAME = \"./corpora/americasnlp2021.txt\"\n",
    "#FILE_NAME = \"/content/drive/MyDrive/Spanish-Tarahumara-Translator/corpora/rarámuri.txt\"\n",
    "#FILE_NAME = \"/content/drive/MyDrive/Spanish-Tarahumara-Translator/corpora/americasnlp2021.txt\"\n",
    "\n",
    "CORPUS_NAME = FILE_NAME.split(sep='/')[-1].split(sep='.')[0]\n",
    "\n",
    "with open(FILE_NAME, mode = 'rt', encoding = 'utf-8') as infile:\n",
    "    lines = infile.read()\n",
    "    sentences = lines.strip().split('\\n')\n",
    "    sentences = [item.split('|') for item in sentences]\n",
    "    spa_tar = np.array(sentences, dtype=object)\n",
    "\n",
    "# Extract Spanish and Tarahumara sentences from corpus\n",
    "spa = spa_tar[:, 0]\n",
    "tar = spa_tar[:, 1]\n",
    "\n",
    "# Remove unnecessary whitespaces\n",
    "spa = np.array([s.strip() for s in spa])\n",
    "tar = np.array([s.strip() for s in tar])\n",
    "\n",
    "# Remove punctuation and lowercase\n",
    "spa = np.array([s.translate(str.maketrans('', '', string.punctuation + \"¿¡\")).lower() for s in spa])\n",
    "tar = np.array([s.translate(str.maketrans('', '', string.punctuation.replace(\"'\", \"\") + \"¿¡\")).lower() for s in tar])\n",
    "\n",
    "# Viewing sentence lengths\n",
    "spa_len = [len(s.split()) for s in spa]\n",
    "tar_len = [len(s.split()) for s in tar]\n",
    "\n",
    "print(f'Maximum length in Spanish: {max(spa_len)}')\n",
    "print(f'Maximum length in Tarahumara: {max(tar_len)}')\n",
    "\n",
    "length_df = pd.DataFrame({'Spanish':spa_len, 'Tarahumara':tar_len})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ba0a7fdb-0c6b-419b-931a-d7d7cfd51e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharey = False, tight_layout = True, figsize = (8, 4))\n",
    "\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "ax[0].hist(length_df['Spanish'], bins = 20)\n",
    "ax[0].set_title('Spanish')\n",
    "ax[0].set_xlabel('Number of words')\n",
    "ax[0].set_ylabel('Number of sentences')\n",
    "ax[1].hist(length_df['Tarahumara'], bins = 20)\n",
    "ax[1].set_title('Tarahumara')\n",
    "ax[1].set_xlabel('Number of words')\n",
    "ax[1].set_ylabel('Number of sentences')\n",
    "#fig.suptitle('Sentence Lengths', fontsize=14)\n",
    "fig.savefig('./images/sentence_lengths_' + CORPUS_NAME + '.png', format = 'png')\n",
    "#fig.savefig('/content/drive/MyDrive/Spanish-Tarahumara-Translator/images/sentence_lengths_' + CORPUS_NAME + '.png', format = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c921ed-6bec-4abc-9d9d-e90a557c443c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "38b74225-135e-4c91-a70c-4b6ddfa723a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMT_Parallel_Corpus:\n",
    "    def __init__(self, filepath = None, problem_type = 'source-target'):\n",
    "        self.filepath = filepath\n",
    "        self.problem_type = problem_type\n",
    "        self.encoder_tokenizer = None\n",
    "        self.decoder_tokenizer = None\n",
    "        self.selection_size = None\n",
    "        self.total_size = None\n",
    "        self.train_set = None\n",
    "        self.validation_set = None\n",
    "        \n",
    "    def text_preprocessing(self, text):\n",
    "\n",
    "        # creating a space between a word and the punctuation following it\n",
    "        # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "        # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "        text = re.sub(r\"([?.¡!,¿])\", r\" \\1 \", text)\n",
    "        text = re.sub(r'[\" \"]+', \" \", text)\n",
    "\n",
    "        # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\") and Spanish special characters\n",
    "        text = re.sub(r\"[^a-zA-Z0-9?.¡!,¿áÁéÉíÍóÓúÚñÑüÜ']+\", \" \", text)\n",
    "\n",
    "        text = text.lower()\n",
    "        text = text.strip()\n",
    "\n",
    "        # adding a start and an end token to the sentence\n",
    "        # so that the model know when to start and stop predicting.\n",
    "        text = \"<SOS> \" + text + \" <EOS>\"\n",
    "        return text\n",
    "\n",
    "    def load_data(self, num_examples):\n",
    "        with open(self.filepath, mode = 'rt', encoding = 'utf-8') as infile:\n",
    "            lines = infile.read()\n",
    "            sentences = lines.strip().split('\\n')\n",
    "            sentences = [item.split('|') for item in sentences]\n",
    "            \n",
    "            self.total_size = len(sentences)\n",
    "            \n",
    "            if self.problem_type == 'source-target':\n",
    "                source = [self.text_preprocessing(source) for source, target, _, _ in sentences[:num_examples]]\n",
    "                target = [self.text_preprocessing(target) for source, target, _, _ in sentences[:num_examples]]\n",
    "            \n",
    "            elif self.problem_type == 'target-source':\n",
    "                source = [self.text_preprocessing(source) for target, source, _, _ in sentences[:num_examples]]\n",
    "                target = [self.text_preprocessing(target) for target, source, _, _ in sentences[:num_examples]]\n",
    "                \n",
    "            else:\n",
    "                print('ERROR:  Unknown problem type!')\n",
    "            \n",
    "            self.selection_size = len(source)\n",
    "\n",
    "            return source, target\n",
    "    \n",
    "    def tokenize(self, text, max_text_length):\n",
    "        \n",
    "        tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
    "        tokenizer.fit_on_texts(text)\n",
    "        tokenizer.word_index['<PAD>'] = 0\n",
    "        sequence_list = tokenizer.texts_to_sequences(text)\n",
    "        \n",
    "        if max_text_length == None:\n",
    "            max_len = max([len(sequence) for sequence in sequence_list])\n",
    "            \n",
    "        else:\n",
    "            max_len = max_text_length\n",
    "\n",
    "        # Pad the sequences to match the longest sequences in the given input\n",
    "        padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequence_list, maxlen = max_len, padding = 'post')\n",
    "\n",
    "        return padded_sequences, tokenizer\n",
    "    \n",
    "    def create_datasets(self, BATCH_SIZE, num_examples = None, max_length = None):\n",
    "        if self.filepath == None:\n",
    "            print('WARNING:  Sets cannot be created.  Variable pathfile not set!')\n",
    "            return None, None, None, None\n",
    "            \n",
    "        else:\n",
    "            input_lang, target_lang = self.load_data(num_examples)\n",
    "            \n",
    "            train_input, val_input, train_target, val_target = train_test_split(input_lang, target_lang, test_size = 0.1, random_state = 100)\n",
    "            self.train_set = pd.DataFrame({'Source':train_input, 'Target':train_target})\n",
    "            self.validation_set = pd.DataFrame({'Source':val_input, 'Target':val_target})\n",
    "        \n",
    "            encoder_sequences, self.encoder_tokenizer = self.tokenize(train_input, max_length)\n",
    "            decoder_sequences, self.decoder_tokenizer = self.tokenize(train_target, max_length)\n",
    "            \n",
    "            # The buffer size must be equal or bigger than the total number of sentence pairs in the dataset\n",
    "            BUFFER_SIZE = len(train_input)\n",
    "\n",
    "            train_dataset = tf.data.Dataset.from_tensor_slices((encoder_sequences, decoder_sequences))\n",
    "            train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)\n",
    "\n",
    "            return train_dataset, self.encoder_tokenizer, self.decoder_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb5ae15-6910-4104-9424-13cf37f89053",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d09e1ae6-980d-4f23-a7cb-dd6d3ba77a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 80\n",
    "BATCH_SIZE = 16\n",
    "EMBEDDING_DIM = 128\n",
    "UNITS = 256\n",
    "NUM_EXAMPLES = None # None -> consider the whole dataset\n",
    "MAX_LENGTH = 20 # None -> consider the whole length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5eb1d-7f21-4bc3-b41a-800794591a36",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8a1a55bb-ed55-4cd6-bf8e-bc94e66b6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = NMT_Parallel_Corpus(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0519dafe-9d04-4d25-8217-2c0b1423cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, tok_enc, tok_dec = corpus.create_datasets(BATCH_SIZE, NUM_EXAMPLES, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b3323065-88cb-42e1-84b4-e4234e550fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus size: 198\n",
      "Selected corpus size: 198\n"
     ]
    }
   ],
   "source": [
    "print(f'Total corpus size: {corpus.total_size}')\n",
    "print(f'Selected corpus size: {corpus.selection_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f45307e5-b9b1-47b5-ac5a-9054f1d71919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 901 unique input tokens.\n",
      "Found 780 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "# Get the word to index mapping for input language\n",
    "word2idx_inputs = tok_enc.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
    "\n",
    "# Get the word to index mapping for output language\n",
    "word2idx_outputs = tok_dec.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "# Map indexes back into real words so we can view the results\n",
    "idx2word_inputs = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_outputs = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "360faa69-91cb-44b0-9f35-45c02da60bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab_size = len(tok_enc.word_index) + 1\n",
    "target_vocab_size = len(tok_dec.word_index) + 1\n",
    "max_length_input = list(train_dataset.as_numpy_iterator())[0][0].shape[1]\n",
    "max_length_target = list(train_dataset.as_numpy_iterator())[0][1].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c5470-1b9b-4855-9f7b-670f9a3aaa17",
   "metadata": {},
   "source": [
    "# Model Architechture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348b47f8-c217-41c7-b3bf-0a23b4f16a4e",
   "metadata": {},
   "source": [
    "## Bidirectional Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "23a7d845-7745-42c0-b6f3-3728bb213912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, encoder_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_units = encoder_units\n",
    "        \n",
    "        # The Embedding layer convets token IDs to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM layer processes those vectors sequentially\n",
    "        self.lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.encoder_units,\n",
    "                                                                       return_sequences = True,\n",
    "                                                                       return_state = True,\n",
    "                                                                       recurrent_initializer = 'glorot_uniform'))\n",
    "    \n",
    "    def call(self, tokens, hidden_state = None):\n",
    "        \n",
    "        # The Embedding layer looks up the embedding for each token\n",
    "        embedding_vector = self.embedding(tokens)\n",
    "        \n",
    "        # None as default causes creation of zero-filled initial state tensors\n",
    "        all_h, fwd_h, fwd_c, bwd_h, bwd_c = self.lstm(embedding_vector, initial_state = hidden_state)\n",
    "        \n",
    "        # Returns the new sequence and its state\n",
    "        return all_h, fwd_h, fwd_c, bwd_h, bwd_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1da6b11-c587-45e7-8d01-e2acf2caeb52",
   "metadata": {},
   "source": [
    "## Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d541e68a-35ec-4fcd-bfdf-1c9fbfc61e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "\n",
    "    def call(self, query, value, mask):\n",
    "\n",
    "        w1_query = self.W1(query)\n",
    "        w2_key = self.W2(value)\n",
    "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
    "        value_mask = mask\n",
    "\n",
    "        context_vector, attention_weights = self.attention(inputs = [w1_query, value, w2_key],\n",
    "                                                           mask = [query_mask, value_mask],\n",
    "                                                           return_attention_scores = True)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7597b9f1-0bd6-499f-9ad6-209448340d84",
   "metadata": {},
   "source": [
    "## Unidirectional Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cfa46a55-b005-47f4-8d3a-4c619fc76a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, target_vocab_size, embedding_dim, decoder_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoder_units = decoder_units\n",
    "    \n",
    "        # The Embedding layer convets token IDs to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, embedding_dim)\n",
    "        \n",
    "        # The LSTM keeps track of what's been generated so far\n",
    "        self.lstm = tf.keras.layers.LSTM(self.decoder_units,\n",
    "                                         return_sequences=True,\n",
    "                                         return_state=True,\n",
    "                                         recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "        # The RNN output will be the query for the attention layer.\n",
    "        self.attention = BahdanauAttention(self.decoder_units*2)\n",
    "\n",
    "        # Used to convert context vector to attention vector\n",
    "        self.Wc = tf.keras.layers.Dense(self.decoder_units*2, \n",
    "                                        activation = tf.math.tanh,\n",
    "                                        use_bias = False)\n",
    "        \n",
    "        # Final Dense layer on which softmax will be applied\n",
    "        self.dense = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, tokens, encoder_output, mask, initial_state = None):\n",
    "        \n",
    "        # Lookup the embeddings\n",
    "        embedding_vector = self.embedding(tokens)\n",
    "        \n",
    "        # Process one step with the LSTM\n",
    "        all_h, h, c = self.lstm(embedding_vector, initial_state = initial_state)\n",
    "        \n",
    "        # Use the RNN output as the query for the attention over the encoder output\n",
    "        context_vector, attention_weights = self.attention(query = all_h, \n",
    "                                                           value = encoder_output, \n",
    "                                                           mask = mask)\n",
    "  \n",
    "        # Concatenate the context_vector and rnn_output\n",
    "        # [ct; ht] shape: (batch t, value_units + query_units)\n",
    "        context_and_rnn_output = tf.concat([context_vector, all_h], axis=-1)\n",
    "\n",
    "        # Calculate attention vector\n",
    "        attention_vector = self.Wc(context_and_rnn_output)\n",
    "  \n",
    "        # Generate logit predictions\n",
    "        logits = self.dense(attention_vector)\n",
    "        \n",
    "        return logits, attention_weights, [h, c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3afb891-c87c-4706-b961-109b8d5a34cc",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c39a93e7-027b-42d6-a070-8845d30d8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'auto')\n",
    "    mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
    "    mask = tf.cast(mask, dtype=tf.int64)  \n",
    "    loss = cross_entropy(y_true=real, y_pred=pred, sample_weight = mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22012b94-d9c1-4e08-999d-c04ff154d980",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "14205fd5-b8e5-4a0d-9902-d0a0f35924cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 3.0842\n",
      "Time taken for 1 epoch 14.160488367080688 [s]\n",
      "\n",
      "Epoch 2 Loss 2.6856\n",
      "Time taken for 1 epoch 13.243027925491333 [s]\n",
      "\n",
      "Epoch 3 Loss 2.3984\n",
      "Time taken for 1 epoch 13.124253273010254 [s]\n",
      "\n",
      "Epoch 4 Loss 2.1909\n",
      "Time taken for 1 epoch 13.292978048324585 [s]\n",
      "\n",
      "Epoch 5 Loss 2.0101\n",
      "Time taken for 1 epoch 12.890253782272339 [s]\n",
      "\n",
      "Epoch 6 Loss 1.8473\n",
      "Time taken for 1 epoch 13.056958198547363 [s]\n",
      "\n",
      "Epoch 7 Loss 1.6611\n",
      "Time taken for 1 epoch 13.551265478134155 [s]\n",
      "\n",
      "Epoch 8 Loss 1.4867\n",
      "Time taken for 1 epoch 13.825700998306274 [s]\n",
      "\n",
      "Epoch 9 Loss 1.2626\n",
      "Time taken for 1 epoch 13.31554102897644 [s]\n",
      "\n",
      "Epoch 10 Loss 1.0887\n",
      "Time taken for 1 epoch 13.047385692596436 [s]\n",
      "\n",
      "Epoch 11 Loss 0.9488\n",
      "Time taken for 1 epoch 13.072902202606201 [s]\n",
      "\n",
      "Epoch 12 Loss 0.7927\n",
      "Time taken for 1 epoch 13.40392518043518 [s]\n",
      "\n",
      "Epoch 13 Loss 0.6413\n",
      "Time taken for 1 epoch 13.21016263961792 [s]\n",
      "\n",
      "Epoch 14 Loss 0.5134\n",
      "Time taken for 1 epoch 13.991487979888916 [s]\n",
      "\n",
      "Epoch 15 Loss 0.4130\n",
      "Time taken for 1 epoch 13.124417781829834 [s]\n",
      "\n",
      "Epoch 16 Loss 0.3303\n",
      "Time taken for 1 epoch 12.090287208557129 [s]\n",
      "\n",
      "Epoch 17 Loss 0.2540\n",
      "Time taken for 1 epoch 13.485867261886597 [s]\n",
      "\n",
      "Epoch 18 Loss 0.1885\n",
      "Time taken for 1 epoch 13.004622220993042 [s]\n",
      "\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x000002300B944880>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\keras\\backend.py\", line 4769, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "Epoch 19 Loss 0.1452\n",
      "Time taken for 1 epoch 16.413573503494263 [s]\n",
      "\n",
      "Epoch 20 Loss 0.1151\n",
      "Time taken for 1 epoch 12.582977533340454 [s]\n",
      "\n",
      "Epoch 21 Loss 0.0965\n",
      "Time taken for 1 epoch 13.423937320709229 [s]\n",
      "\n",
      "Epoch 22 Loss 0.0791\n",
      "Time taken for 1 epoch 13.648864984512329 [s]\n",
      "\n",
      "Epoch 23 Loss 0.0620\n",
      "Time taken for 1 epoch 13.358798742294312 [s]\n",
      "\n",
      "Epoch 24 Loss 0.0514\n",
      "Time taken for 1 epoch 13.49468183517456 [s]\n",
      "\n",
      "Epoch 25 Loss 0.0421\n",
      "Time taken for 1 epoch 12.862706184387207 [s]\n",
      "\n",
      "Epoch 26 Loss 0.0364\n",
      "Time taken for 1 epoch 13.807934999465942 [s]\n",
      "\n",
      "Epoch 27 Loss 0.0313\n",
      "Time taken for 1 epoch 12.980567455291748 [s]\n",
      "\n",
      "Epoch 28 Loss 0.0271\n",
      "Time taken for 1 epoch 11.2416672706604 [s]\n",
      "\n",
      "Epoch 29 Loss 0.0253\n",
      "Time taken for 1 epoch 12.870656490325928 [s]\n",
      "\n",
      "Epoch 30 Loss 0.0229\n",
      "Time taken for 1 epoch 13.226862668991089 [s]\n",
      "\n",
      "Epoch 31 Loss 0.0207\n",
      "Time taken for 1 epoch 12.831777334213257 [s]\n",
      "\n",
      "Epoch 32 Loss 0.0195\n",
      "Time taken for 1 epoch 13.096403360366821 [s]\n",
      "\n",
      "Epoch 33 Loss 0.0181\n",
      "Time taken for 1 epoch 13.864872932434082 [s]\n",
      "\n",
      "Epoch 34 Loss 0.0168\n",
      "Time taken for 1 epoch 12.427241802215576 [s]\n",
      "\n",
      "Epoch 35 Loss 0.0159\n",
      "Time taken for 1 epoch 13.512871265411377 [s]\n",
      "\n",
      "Epoch 36 Loss 0.0149\n",
      "Time taken for 1 epoch 13.775083541870117 [s]\n",
      "\n",
      "Epoch 37 Loss 0.0143\n",
      "Time taken for 1 epoch 13.820910215377808 [s]\n",
      "\n",
      "Epoch 38 Loss 0.0134\n",
      "Time taken for 1 epoch 13.5720853805542 [s]\n",
      "\n",
      "Epoch 39 Loss 0.0129\n",
      "Time taken for 1 epoch 13.625517845153809 [s]\n",
      "\n",
      "Epoch 40 Loss 0.0122\n",
      "Time taken for 1 epoch 13.500192403793335 [s]\n",
      "\n",
      "Epoch 41 Loss 0.0117\n",
      "Time taken for 1 epoch 13.580560207366943 [s]\n",
      "\n",
      "Epoch 42 Loss 0.0113\n",
      "Time taken for 1 epoch 18.121113538742065 [s]\n",
      "\n",
      "Epoch 43 Loss 0.0108\n",
      "Time taken for 1 epoch 13.568270921707153 [s]\n",
      "\n",
      "Epoch 44 Loss 0.0107\n",
      "Time taken for 1 epoch 13.912161827087402 [s]\n",
      "\n",
      "Epoch 45 Loss 0.0101\n",
      "Time taken for 1 epoch 14.210365056991577 [s]\n",
      "\n",
      "Epoch 46 Loss 0.0097\n",
      "Time taken for 1 epoch 13.682002067565918 [s]\n",
      "\n",
      "Epoch 47 Loss 0.0095\n",
      "Time taken for 1 epoch 13.516088962554932 [s]\n",
      "\n",
      "Epoch 48 Loss 0.0090\n",
      "Time taken for 1 epoch 14.027849197387695 [s]\n",
      "\n",
      "Epoch 49 Loss 0.0089\n",
      "Time taken for 1 epoch 13.772121906280518 [s]\n",
      "\n",
      "Epoch 50 Loss 0.0084\n",
      "Time taken for 1 epoch 13.590215682983398 [s]\n",
      "\n",
      "Epoch 51 Loss 0.0085\n",
      "Time taken for 1 epoch 13.64436388015747 [s]\n",
      "\n",
      "Epoch 52 Loss 0.0081\n",
      "Time taken for 1 epoch 13.66825532913208 [s]\n",
      "\n",
      "Epoch 53 Loss 0.0079\n",
      "Time taken for 1 epoch 12.71885871887207 [s]\n",
      "\n",
      "Epoch 54 Loss 0.0077\n",
      "Time taken for 1 epoch 13.527731895446777 [s]\n",
      "\n",
      "Epoch 55 Loss 0.0076\n",
      "Time taken for 1 epoch 13.166555881500244 [s]\n",
      "\n",
      "Epoch 56 Loss 0.0072\n",
      "Time taken for 1 epoch 14.085379600524902 [s]\n",
      "\n",
      "Epoch 57 Loss 0.0069\n",
      "Time taken for 1 epoch 13.951338052749634 [s]\n",
      "\n",
      "Epoch 58 Loss 0.0070\n",
      "Time taken for 1 epoch 13.768662691116333 [s]\n",
      "\n",
      "Epoch 59 Loss 0.0068\n",
      "Time taken for 1 epoch 14.119319438934326 [s]\n",
      "\n",
      "Epoch 60 Loss 0.0068\n",
      "Time taken for 1 epoch 12.927029132843018 [s]\n",
      "\n",
      "Epoch 61 Loss 0.0066\n",
      "Time taken for 1 epoch 12.591047763824463 [s]\n",
      "\n",
      "Epoch 62 Loss 0.0065\n",
      "Time taken for 1 epoch 13.689647674560547 [s]\n",
      "\n",
      "Epoch 63 Loss 0.0062\n",
      "Time taken for 1 epoch 12.534985780715942 [s]\n",
      "\n",
      "Epoch 64 Loss 0.0063\n",
      "Time taken for 1 epoch 13.525602579116821 [s]\n",
      "\n",
      "Epoch 65 Loss 0.0059\n",
      "Time taken for 1 epoch 15.797977447509766 [s]\n",
      "\n",
      "Epoch 66 Loss 0.0058\n",
      "Time taken for 1 epoch 13.489704370498657 [s]\n",
      "\n",
      "Epoch 67 Loss 0.0058\n",
      "Time taken for 1 epoch 13.382912158966064 [s]\n",
      "\n",
      "Epoch 68 Loss 0.0058\n",
      "Time taken for 1 epoch 13.461451530456543 [s]\n",
      "\n",
      "Epoch 69 Loss 0.0055\n",
      "Time taken for 1 epoch 13.973458528518677 [s]\n",
      "\n",
      "Epoch 70 Loss 0.0055\n",
      "Time taken for 1 epoch 13.039662599563599 [s]\n",
      "\n",
      "Epoch 71 Loss 0.0054\n",
      "Time taken for 1 epoch 12.921226501464844 [s]\n",
      "\n",
      "Epoch 72 Loss 0.0052\n",
      "Time taken for 1 epoch 12.634890794754028 [s]\n",
      "\n",
      "Epoch 73 Loss 0.0052\n",
      "Time taken for 1 epoch 12.659306764602661 [s]\n",
      "\n",
      "Epoch 74 Loss 0.0051\n",
      "Time taken for 1 epoch 12.99581789970398 [s]\n",
      "\n",
      "Epoch 75 Loss 0.0050\n",
      "Time taken for 1 epoch 11.607892274856567 [s]\n",
      "\n",
      "Epoch 76 Loss 0.0051\n",
      "Time taken for 1 epoch 13.40465784072876 [s]\n",
      "\n",
      "Epoch 77 Loss 0.0050\n",
      "Time taken for 1 epoch 12.433041334152222 [s]\n",
      "\n",
      "Epoch 78 Loss 0.0048\n",
      "Time taken for 1 epoch 13.59566593170166 [s]\n",
      "\n",
      "Epoch 79 Loss 0.0047\n",
      "Time taken for 1 epoch 12.839808702468872 [s]\n",
      "\n",
      "Epoch 80 Loss 0.0047\n",
      "Time taken for 1 epoch 13.105552434921265 [s]\n",
      "\n",
      "Total training time: 17.901860328515372 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(input_vocab_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\n",
    "decoder = Decoder(target_vocab_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.005, beta_1 = 0.9, beta_2 = 0.999, decay = 0.01)\n",
    "loss_history = []\n",
    "\n",
    "# Create a checkpoint object to save the model\n",
    "checkpoint_dir = './training_ckpt_seq2seq'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(train_dataset):\n",
    "        \n",
    "        # Convert IDs to masks.\n",
    "        input_mask = inp != 0\n",
    "        target_mask = targ != 0\n",
    "        \n",
    "        loss = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            enc_output, enc_fwd_h, enc_fwd_c, enc_bwd_h, enc_bwd_c = encoder(inp)\n",
    "            #dec_state = [enc_fwd_h, enc_fwd_c, enc_bwd_h, enc_bwd_c]\n",
    "            dec_state = [enc_bwd_h, enc_bwd_c]  # Initialize with backward hidden state (Bahdanau et al., 2016)\n",
    "            dec_input = tf.expand_dims([word2idx_outputs['<sos>']] * BATCH_SIZE, 1)\n",
    "            \n",
    "            for t in range(1, targ.shape[1]):\n",
    "                \n",
    "                # passing enc_output to the decoder\n",
    "                logits, attention_weights, dec_state = decoder(dec_input, enc_output, input_mask, dec_state)\n",
    "                \n",
    "                # Calculate cumulative loss\n",
    "                loss += loss_function(targ[:, t], logits)\n",
    "                \n",
    "                # Apply teacher forcing:  feeding the target as the next input\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "            \n",
    "        total_loss += (loss / int(targ.shape[1]))\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "    loss_history.append(total_loss / len(train_dataset))\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / len(train_dataset)))\n",
    "    print('Time taken for 1 epoch {} [s]\\n'.format(time.time() - start))\n",
    "print(f'Total training time: {(time.time() - start_time)/60} minutes\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1c070680-3835-4f1d-bfa1-87d3bae7a882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, tight_layout = True, figsize = (6, 4))\n",
    "plt.plot(loss_history)\n",
    "plt.legend(['Training'])\n",
    "plt.title(CORPUS_NAME + ' Corpus')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "if MAX_LENGTH == None:\n",
    "    length = 'max'\n",
    "else:\n",
    "    length = str(MAX_LENGTH)\n",
    "\n",
    "fig.savefig('./images/' + CORPUS_NAME + '_loss_len_' + length + '_rnn2.png', format = 'png')\n",
    "#fig.savefig('/content/drive/MyDrive/Spanish-Tarahumara-Translator/images/' + CORPUS_NAME + '_loss_len_' + length + '_rnn2.png', format = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5376bd-c032-46f8-aef2-992c7fedc76c",
   "metadata": {},
   "source": [
    "# Prediction Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c2f44da8-468d-4d19-848c-98925df0a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_text, encoder, decoder, input_max_len, output_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs):\n",
    "    if input_text is None:\n",
    "        input_text = input_data[np.random.choice(len(input_data))]\n",
    "    \n",
    "    # Tokenize the input sequence\n",
    "    input_seq = tokenizer_inputs.texts_to_sequences([input_text])\n",
    "    \n",
    "    # Pad the sentence\n",
    "    input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=input_max_len, padding='post')\n",
    "    \n",
    "    # Consider only unpadded part of the sequence\n",
    "    input_mask = input_seq != 0\n",
    "    \n",
    "    # Generate encoder output\n",
    "    en_outputs = encoder(tf.constant(input_seq))\n",
    "    \n",
    "    # Create the decoder input (<SOS> token)\n",
    "    de_input = tf.constant([[word2idx_outputs['<sos>']]])\n",
    "    \n",
    "    # Set the decoder states to the encoder vector or encoder hidden state\n",
    "    dec_state = en_outputs[1:3]\n",
    "    #dec_state = en_outputs[3:5] # Using the backward state improves dramatically prediction quality\n",
    "    \n",
    "    out_words = []\n",
    "    while True:\n",
    "        # Decode and get the output probabilities\n",
    "        de_output, _, dec_state = decoder(de_input, en_outputs[0], input_mask, dec_state)\n",
    "        \n",
    "        # Select the word with the highest probability\n",
    "        de_input = tf.argmax(de_output, -1)\n",
    "        \n",
    "        # Append the word to the predicted output\n",
    "        out_words.append(idx2word_outputs[de_input.numpy()[0][0]])\n",
    "        \n",
    "        # Finish when <EOS> token is found or the max length is reached\n",
    "        if out_words[-1] == '<eos>' or len(out_words) >= output_max_len:\n",
    "            break\n",
    "\n",
    "    translation = ' '.join(out_words)\n",
    "    return translation, out_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa1f32e-03ce-4fea-a051-0f4f606434fb",
   "metadata": {},
   "source": [
    "## Evaluating Predictions with Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "be7b1ae6-9d1a-4685-8cc4-18689541518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = corpus.train_set['Source'].apply(lambda x : predict(x, encoder, decoder, max_length_input, max_length_target, tok_enc, word2idx_outputs, idx2word_outputs)[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "60ac29ea-3d83-46d6-9ec3-bfeb9471cc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>BLEU-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; ¿ dónde vive usted ? &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; ¿ comi bité mujé ? &lt;EOS&gt;</td>\n",
       "      <td>¿ ¿ comi bité ? &lt;eos&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.221339e-77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; a lo que canta un pájaro . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; mapu a'lí ta nalépua chulukí jíti . &lt;EOS&gt;</td>\n",
       "      <td>mapu ta nalépua chulukí jíti . &lt;eos&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; está haciendo mucho frío . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; hue ruluá . &lt;EOS&gt;</td>\n",
       "      <td>hue hue ruluá . &lt;eos&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.491668e-154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; tus abuelos maternos . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; kému apalócha a'lí kému u'sú . &lt;EOS&gt;</td>\n",
       "      <td>kému kému u'sú . &lt;eos&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; el tarahumar con el sonido de la piel despierta a sus padres &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; ralámuli wichí anéala kiti busurébi e'wénuala &lt;EOS&gt;</td>\n",
       "      <td>wichí anéala anéala kiti busurébi e'wénuala &lt;eos&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     Source  \\\n",
       "0                                          <SOS> ¿ dónde vive usted ? <EOS>   \n",
       "1                                    <SOS> a lo que canta un pájaro . <EOS>   \n",
       "2                                    <SOS> está haciendo mucho frío . <EOS>   \n",
       "3                                        <SOS> tus abuelos maternos . <EOS>   \n",
       "4  <SOS> el tarahumar con el sonido de la piel despierta a sus padres <EOS>   \n",
       "\n",
       "                                                      Target  \\\n",
       "0                             <SOS> ¿ comi bité mujé ? <EOS>   \n",
       "1            <SOS> mapu a'lí ta nalépua chulukí jíti . <EOS>   \n",
       "2                                    <SOS> hue ruluá . <EOS>   \n",
       "3                 <SOS> kému apalócha a'lí kému u'sú . <EOS>   \n",
       "4  <SOS> ralámuli wichí anéala kiti busurébi e'wénuala <EOS>   \n",
       "\n",
       "                                         Predictions  BLEU-1         BLEU-4  \n",
       "0                              ¿ ¿ comi bité ? <eos>     1.0   1.221339e-77  \n",
       "1               mapu ta nalépua chulukí jíti . <eos>     1.0   1.000000e+00  \n",
       "2                              hue hue ruluá . <eos>     1.0  1.491668e-154  \n",
       "3                             kému kému u'sú . <eos>     1.0   1.000000e+00  \n",
       "4  wichí anéala anéala kiti busurébi e'wénuala <eos>     1.0   1.000000e+00  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "train_df = corpus.train_set\n",
    "train_df['Predictions'] = predictions\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf565a-b356-48ee-8c60-0c100e6c1e2e",
   "metadata": {},
   "source": [
    "### BLEU Scores Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "73ea9fbe-efa0-449a-83ab-26844100cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_bleu = corpus.train_set['Source'].apply(lambda x : predict(x,encoder, decoder, max_length_input, max_length_target, tok_enc, word2idx_outputs, idx2word_outputs)[1]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb642f0-1400-4a3c-b5d3-8dca08d58d3c",
   "metadata": {},
   "source": [
    "#### Translation and Target Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "175b7f82-5274-4cda-ab71-2a5b1e30dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction output preprocessing for calculating BLEU score\n",
    "for i in range(len(candidates_bleu)):\n",
    "    # Remove duplicate elements like commas\n",
    "    candidates_bleu[i] = list(dict.fromkeys(candidates_bleu[i]))\n",
    "    # Remove <EOS> token\n",
    "    if '<eos>' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('<eos>')\n",
    "    # Remove special punctuation characters\n",
    "    if '.' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('.')\n",
    "    if ',' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove(',')\n",
    "    if '!' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('!')\n",
    "    if '¡' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('¡')\n",
    "    if '?' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('?')\n",
    "    if '¿' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('¿')\n",
    "\n",
    "# Target preprocessing for calculating BLEU score\n",
    "references_bleu = train_df['Target'].to_list()\n",
    "\n",
    "for i in range(len(references_bleu)):\n",
    "    references_bleu[i] = references_bleu[i].split()\n",
    "    # Remove duplicate elements like commas\n",
    "    references_bleu[i] = list(dict.fromkeys(references_bleu[i]))\n",
    "    # Remove <SOS> token\n",
    "    references_bleu[i].remove('<SOS>')\n",
    "    # Remove <EOS> token\n",
    "    references_bleu[i].remove('<EOS>')\n",
    "    # Remove special punctuation characters\n",
    "    if '.' in references_bleu[i]:\n",
    "        references_bleu[i].remove('.')\n",
    "    if ',' in references_bleu[i]:\n",
    "        references_bleu[i].remove(',')\n",
    "    if '!' in references_bleu[i]:\n",
    "        references_bleu[i].remove('!')\n",
    "    if '¡' in references_bleu[i]:\n",
    "        references_bleu[i].remove('¡')\n",
    "    if '?' in references_bleu[i]:\n",
    "        references_bleu[i].remove('?')\n",
    "    if '¿' in references_bleu[i]:\n",
    "        references_bleu[i].remove('¿')\n",
    "        \n",
    "references_bleu_train = list()\n",
    "for i in range(len(references_bleu)):\n",
    "    references_bleu_train.append(list())\n",
    "    references_bleu_train[i].append(references_bleu[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9f90c-3919-4214-bf5b-ffa4e22a162d",
   "metadata": {},
   "source": [
    "* **Corpus BLEU Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1c283120-e0d5-49f4-b1c5-f18fcab8c8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU-1 score: 0.24023684812049728\n",
      "Corpus BLEU-4 score: 0.12583549206414846\n"
     ]
    }
   ],
   "source": [
    "score = corpus_bleu(references_bleu_train, candidates_bleu, weights = (1,0,0,0))\n",
    "print(f'Corpus BLEU-1 score: {score}')\n",
    "score = corpus_bleu(references_bleu_train, candidates_bleu)\n",
    "print(f'Corpus BLEU-4 score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd3462-d51e-49a6-b27c-b4c78f26df02",
   "metadata": {},
   "source": [
    "* **Sentence BLEU Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "39984968-f2ff-4fd7-a5f9-f116b86f1854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>BLEU-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; ¿ dónde vive usted ? &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; ¿ comi bité mujé ? &lt;EOS&gt;</td>\n",
       "      <td>¿ ¿ comi bité ? &lt;eos&gt;</td>\n",
       "      <td>0.606531</td>\n",
       "      <td>9.047425e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; a lo que canta un pájaro . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; mapu a'lí ta nalépua chulukí jíti . &lt;EOS&gt;</td>\n",
       "      <td>mapu ta nalépua chulukí jíti . &lt;eos&gt;</td>\n",
       "      <td>0.818731</td>\n",
       "      <td>5.789301e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; está haciendo mucho frío . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; hue ruluá . &lt;EOS&gt;</td>\n",
       "      <td>hue hue ruluá . &lt;eos&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.491668e-154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; tus abuelos maternos . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; kému apalócha a'lí kému u'sú . &lt;EOS&gt;</td>\n",
       "      <td>kému kému u'sú . &lt;eos&gt;</td>\n",
       "      <td>0.367879</td>\n",
       "      <td>6.702145e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; el tarahumar con el sonido de la piel despierta a sus padres &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; ralámuli wichí anéala kiti busurébi e'wénuala &lt;EOS&gt;</td>\n",
       "      <td>wichí anéala anéala kiti busurébi e'wénuala &lt;eos&gt;</td>\n",
       "      <td>0.818731</td>\n",
       "      <td>8.187308e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     Source  \\\n",
       "0                                          <SOS> ¿ dónde vive usted ? <EOS>   \n",
       "1                                    <SOS> a lo que canta un pájaro . <EOS>   \n",
       "2                                    <SOS> está haciendo mucho frío . <EOS>   \n",
       "3                                        <SOS> tus abuelos maternos . <EOS>   \n",
       "4  <SOS> el tarahumar con el sonido de la piel despierta a sus padres <EOS>   \n",
       "\n",
       "                                                      Target  \\\n",
       "0                             <SOS> ¿ comi bité mujé ? <EOS>   \n",
       "1            <SOS> mapu a'lí ta nalépua chulukí jíti . <EOS>   \n",
       "2                                    <SOS> hue ruluá . <EOS>   \n",
       "3                 <SOS> kému apalócha a'lí kému u'sú . <EOS>   \n",
       "4  <SOS> ralámuli wichí anéala kiti busurébi e'wénuala <EOS>   \n",
       "\n",
       "                                         Predictions    BLEU-1         BLEU-4  \n",
       "0                              ¿ ¿ comi bité ? <eos>  0.606531  9.047425e-155  \n",
       "1               mapu ta nalépua chulukí jíti . <eos>  0.818731   5.789301e-01  \n",
       "2                              hue hue ruluá . <eos>  1.000000  1.491668e-154  \n",
       "3                             kému kému u'sú . <eos>  0.367879  6.702145e-232  \n",
       "4  wichí anéala anéala kiti busurébi e'wénuala <eos>  0.818731   8.187308e-01  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu_scores = []\n",
    "for i in range(len(references_bleu)):\n",
    "    sentence_bleu_scores.append(sentence_bleu(references_bleu_train[i], candidates_bleu[i], weights = (1,0,0,0)))\n",
    "train_df['BLEU-1'] = sentence_bleu_scores\n",
    "\n",
    "sentence_bleu_scores = []\n",
    "for i in range(len(references_bleu)):\n",
    "    sentence_bleu_scores.append(sentence_bleu(references_bleu_train[i], candidates_bleu[i])) \n",
    "train_df['BLEU-4'] = sentence_bleu_scores\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a1ad443f-6ae9-498f-b4b3-56f49f613a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_excel('./results/train_' + CORPUS_NAME + '_len_' + length + '_rnn2.xlsx')\n",
    "#train_df.to_excel('/content/drive/MyDrive/Spanish-Tarahumara-Translator/results/train_' + CORPUS_NAME + '_len_' + length + '_rnn2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265bac8-e124-4839-a281-2849483215bc",
   "metadata": {},
   "source": [
    "## Predictions with Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e6ebd2d3-d17c-49b9-81f9-575e7571d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = corpus.validation_set['Source'].apply(lambda x : predict(x, encoder, decoder, max_length_input, max_length_target, tok_enc, word2idx_outputs, idx2word_outputs)[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "aa1163f8-b2ae-49a0-86e3-e3b3f0999e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>BLEU-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; artículo 2o . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; osirúa'mi 2 . &lt;EOS&gt;</td>\n",
       "      <td>osirúa'mi rayena . &lt;eos&gt;</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.531972e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; ya haz nacer al maíz y a las demás plantas . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; má ochébi suunú a'lí jalé chó reyawi . &lt;EOS&gt;</td>\n",
       "      <td>ralámuli anéala ralámuli kiti natéa'mi . &lt;eos&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; para que comience a nacer la hierba &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; mapuliká reyáwi chotáma a'wiyá &lt;EOS&gt;</td>\n",
       "      <td>mapuliká suunú ratáami rayena . &lt;eos&gt;</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.054769e-154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; despiertan alegres al escuchar el eco . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; népi busuré kaníla kipúu rampóli kebáala . &lt;EOS&gt;</td>\n",
       "      <td>ba'wéchi . &lt;eos&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; fue así como fueron creados los rarámuri y los chabochi &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; echiriká iwítali rarámuri alí chabochi &lt;EOS&gt;</td>\n",
       "      <td>churegá chabochi &lt;eos&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Source  \\\n",
       "0                                            <SOS> artículo 2o . <EOS>   \n",
       "1             <SOS> ya haz nacer al maíz y a las demás plantas . <EOS>   \n",
       "2                      <SOS> para que comience a nacer la hierba <EOS>   \n",
       "3                  <SOS> despiertan alegres al escuchar el eco . <EOS>   \n",
       "4  <SOS> fue así como fueron creados los rarámuri y los chabochi <EOS>   \n",
       "\n",
       "                                                   Target  \\\n",
       "0                               <SOS> osirúa'mi 2 . <EOS>   \n",
       "1      <SOS> má ochébi suunú a'lí jalé chó reyawi . <EOS>   \n",
       "2              <SOS> mapuliká reyáwi chotáma a'wiyá <EOS>   \n",
       "3  <SOS> népi busuré kaníla kipúu rampóli kebáala . <EOS>   \n",
       "4      <SOS> echiriká iwítali rarámuri alí chabochi <EOS>   \n",
       "\n",
       "                                      Predictions  BLEU-1         BLEU-4  \n",
       "0                        osirúa'mi rayena . <eos>    0.50  1.531972e-231  \n",
       "1  ralámuli anéala ralámuli kiti natéa'mi . <eos>    0.00   0.000000e+00  \n",
       "2           mapuliká suunú ratáami rayena . <eos>    0.75  1.054769e-154  \n",
       "3                                ba'wéchi . <eos>    0.00   0.000000e+00  \n",
       "4                          churegá chabochi <eos>    0.00   0.000000e+00  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = corpus.validation_set\n",
    "validation_df['Predictions'] = predictions\n",
    "validation_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cef71f-6262-4d7e-997d-d61a64747c7b",
   "metadata": {},
   "source": [
    "### BLEU Score (Validation Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0dc63c2e-16ec-4be2-8fdf-a5a6e02bae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_bleu = corpus.validation_set['Source'].apply(lambda x : predict(x, encoder, decoder, max_length_input, max_length_target, tok_enc, word2idx_outputs, idx2word_outputs)[1]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdfbf44-ed23-4151-b38d-601eed912150",
   "metadata": {},
   "source": [
    "#### Translation and Target Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "20da5ab8-2e01-4e9a-aab1-bcfe30c9ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction output preprocessing for calculating BLEU score\n",
    "for i in range(len(candidates_bleu)):\n",
    "    # Remove duplicate elements like commas\n",
    "    candidates_bleu[i] = list(dict.fromkeys(candidates_bleu[i]))\n",
    "    # Remove <EOS> token\n",
    "    if '<eos>' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('<eos>')\n",
    "    # Remove special punctuation characters\n",
    "    if '.' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('.')\n",
    "    if ',' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove(',')\n",
    "    if '!' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('!')\n",
    "    if '¡' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('¡')\n",
    "    if '?' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('?')\n",
    "    if '¿' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('¿')\n",
    "        \n",
    "# Target preprocessing for calculating BLEU score\n",
    "references_bleu = validation_df['Target'].to_list()\n",
    "\n",
    "for i in range(len(references_bleu)):\n",
    "    references_bleu[i] = references_bleu[i].split()\n",
    "    # Remove duplicate elements like commas\n",
    "    references_bleu[i] = list(dict.fromkeys(references_bleu[i]))\n",
    "    # Remove <SOS> token\n",
    "    references_bleu[i].remove('<SOS>')\n",
    "    # Remove <EOS> token\n",
    "    references_bleu[i].remove('<EOS>')\n",
    "    # Remove special punctuation characters\n",
    "    if '.' in references_bleu[i]:\n",
    "        references_bleu[i].remove('.')\n",
    "    if ',' in references_bleu[i]:\n",
    "        references_bleu[i].remove(',')\n",
    "    if '!' in references_bleu[i]:\n",
    "        references_bleu[i].remove('!')\n",
    "    if '¡' in references_bleu[i]:\n",
    "        references_bleu[i].remove('¡')\n",
    "    if '?' in references_bleu[i]:\n",
    "        references_bleu[i].remove('?')\n",
    "    if '¿' in references_bleu[i]:\n",
    "        references_bleu[i].remove('¿')\n",
    "        \n",
    "references_bleu_validation = list()\n",
    "for i in range(len(references_bleu)):\n",
    "    references_bleu_validation.append(list())\n",
    "    references_bleu_validation[i].append(references_bleu[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c13d1b-6493-4170-971b-b0944a299356",
   "metadata": {},
   "source": [
    "* **Corpus BLEU Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5cc68c81-2f5f-448a-96be-25de388d06be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU-1 score: 0.0329605355343983\n",
      "Corpus BLEU-4 score: 1.8398083737400347e-232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "score = corpus_bleu(references_bleu_validation, candidates_bleu, weights = (1,0,0,0))\n",
    "print(f'Corpus BLEU-1 score: {score}')\n",
    "score = corpus_bleu(references_bleu_validation, candidates_bleu)\n",
    "print(f'Corpus BLEU-4 score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd36c6-6f2f-406a-8b6f-0b4a7b797e1f",
   "metadata": {},
   "source": [
    "* **Sentence BLEU Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9ae07863-a2b2-413e-ba75-694f0a4a069f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>BLEU-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; artículo 2o . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; osirúa'mi 2 . &lt;EOS&gt;</td>\n",
       "      <td>osirúa'mi rayena . &lt;eos&gt;</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.531972e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; ya haz nacer al maíz y a las demás plantas . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; má ochébi suunú a'lí jalé chó reyawi . &lt;EOS&gt;</td>\n",
       "      <td>ralámuli anéala ralámuli kiti natéa'mi . &lt;eos&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; para que comience a nacer la hierba &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; mapuliká reyáwi chotáma a'wiyá &lt;EOS&gt;</td>\n",
       "      <td>mapuliká suunú ratáami rayena . &lt;eos&gt;</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.288230e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; despiertan alegres al escuchar el eco . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; népi busuré kaníla kipúu rampóli kebáala . &lt;EOS&gt;</td>\n",
       "      <td>ba'wéchi . &lt;eos&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; fue así como fueron creados los rarámuri y los chabochi &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; echiriká iwítali rarámuri alí chabochi &lt;EOS&gt;</td>\n",
       "      <td>churegá chabochi &lt;eos&gt;</td>\n",
       "      <td>0.111565</td>\n",
       "      <td>3.418292e-232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Source  \\\n",
       "0                                            <SOS> artículo 2o . <EOS>   \n",
       "1             <SOS> ya haz nacer al maíz y a las demás plantas . <EOS>   \n",
       "2                      <SOS> para que comience a nacer la hierba <EOS>   \n",
       "3                  <SOS> despiertan alegres al escuchar el eco . <EOS>   \n",
       "4  <SOS> fue así como fueron creados los rarámuri y los chabochi <EOS>   \n",
       "\n",
       "                                                   Target  \\\n",
       "0                               <SOS> osirúa'mi 2 . <EOS>   \n",
       "1      <SOS> má ochébi suunú a'lí jalé chó reyawi . <EOS>   \n",
       "2              <SOS> mapuliká reyáwi chotáma a'wiyá <EOS>   \n",
       "3  <SOS> népi busuré kaníla kipúu rampóli kebáala . <EOS>   \n",
       "4      <SOS> echiriká iwítali rarámuri alí chabochi <EOS>   \n",
       "\n",
       "                                      Predictions    BLEU-1         BLEU-4  \n",
       "0                        osirúa'mi rayena . <eos>  0.500000  1.531972e-231  \n",
       "1  ralámuli anéala ralámuli kiti natéa'mi . <eos>  0.000000   0.000000e+00  \n",
       "2           mapuliká suunú ratáami rayena . <eos>  0.250000  1.288230e-231  \n",
       "3                                ba'wéchi . <eos>  0.000000   0.000000e+00  \n",
       "4                          churegá chabochi <eos>  0.111565  3.418292e-232  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu_scores = []\n",
    "for i in range(len(references_bleu)):\n",
    "    sentence_bleu_scores.append(sentence_bleu(references_bleu_validation[i], candidates_bleu[i], weights = (1,0,0,0)))\n",
    "validation_df['BLEU-1'] = sentence_bleu_scores\n",
    "\n",
    "sentence_bleu_scores = []\n",
    "for i in range(len(references_bleu)):\n",
    "    sentence_bleu_scores.append(sentence_bleu(references_bleu_validation[i], candidates_bleu[i]))\n",
    "validation_df['BLEU-4'] = sentence_bleu_scores\n",
    "validation_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a859f197-5c37-44f0-93fc-b2a56794cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.to_excel('./results/val_' + CORPUS_NAME + '_len_' + length + '_rnn2.xlsx')\n",
    "#validation_df.to_excel('/content/drive/MyDrive/Spanish-Tarahumara-Translator/results/val_' + CORPUS_NAME + '_len_' + length + '_rnn2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682de9a-8deb-490b-9328-814d9bbcbd71",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<li><a href=\"https://aclanthology.org/D14-1179\">Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation</a> (Cho et al., EMNLP 2014)</li>\n",
    "\n",
    "<li><a href=\"https://arxiv.org/abs/1409.0473\">Neural Machine Translation by Jointly Learning to Align and Translate</a> (Bahdanau et al., ICLR 2015)</li>\n",
    "\n",
    "<li><a href=\"https://arxiv.org/abs/1809.06662\">Bidirectional Attentional Encoder-Decoder Model and Bidirectional Beam Search for Abstractive Summarization</a> (Al-Sabahi et al., arXiv 2018)</li>\n",
    "\n",
    "<li><a href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/nmt_with_attention.ipynb\">TensorFlow Tutorial:  Neural Machine Translation with Attention</a> (GitHub Repository)</li>\n",
    "\n",
    "<li><a href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb\">TensorFlow Tutorial:  Text Generation with an RNN</a> (GitHub Repository)</li>\n",
    "\n",
    "<li><a href=\"https://colab.research.google.com/github/tensorflow/addons/blob/master/docs/tutorials/networks_seq2seq_nmt.ipynb\">TensorFlow Addons Networks:  Sequence-to-Sequence NMT with Attention Mechanism</a> (GitHub Repository)</li>\n",
    "\n",
    "<li><a href=\"https://github.com/edumunozsala/NMT-encoder-decoder-Attention\">NMT-encoder-decoder-Attention</a> (GitHub Repository)</li>\n",
    "\n",
    "<li><a href=\"https://www.kaggle.com/code/rizdelhi/end-to-end-nlp-4-attention-and-transformer\">end-to-end-nlp-4-attention-and-transformer</a> (Kaggle Notebook)</li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMT",
   "language": "python",
   "name": "smt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
