{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a1409d-0505-4751-81fe-fd6657cf4747",
   "metadata": {},
   "source": [
    "<div class=\"infotext\" style='padding:0.1em; color:#000000'>\n",
    "<span>\n",
    "<p style='margin-top:1em; text-align:center'><font size=\"10\"><b>Spanish-to-Tarahumara Translation</b></font></p>\n",
    "    <p style='margin-top:1em; text-align:center'><font size=\"5\"><b>Forward LSTM Encoder - Forward LSTM Decoder</b></font></p>\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "34ced159-8e20-47dc-9243-9d1864886e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spanish-Tarahumara-Translator:  Forward LSTM Encoder - Forward LSTM Decoder\n",
    "# Copyright (C) 2022  Eduardo Aguilar Moreno\n",
    "\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb78928-1279-4495-b68c-fc2e04b8033a",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "926bc360-855a-4168-99a6-324276781193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e11bc49b-20c5-493f-b175-ad6b17970a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "6b723000-de41-4e1b-bcbf-b491ace82a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235c854d-9c62-40e7-b298-953b8323e2a4",
   "metadata": {},
   "source": [
    "# Viewing Sentence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "5de5dbad-3883-4231-98df-051121fdae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length in Spanish: 83\n",
      "Maximum length in Tarahumara: 103\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME = \"./corpora/rarámuri.txt\"\n",
    "#FILE_NAME = \"./corpora/americasnlp2021.txt\"\n",
    "#FILE_NAME = \"/content/drive/MyDrive/Spanish-Tarahumara-Translator/corpora/rarámuri.txt\"\n",
    "#FILE_NAME = \"/content/drive/MyDrive/Spanish-Tarahumara-Translator/corpora/americasnlp2021.txt\"\n",
    "\n",
    "CORPUS_NAME = FILE_NAME.split(sep='/')[-1].split(sep='.')[0]\n",
    "\n",
    "with open(FILE_NAME, mode = 'rt', encoding = 'utf-8') as infile:\n",
    "    lines = infile.read()\n",
    "    sentences = lines.strip().split('\\n')\n",
    "    sentences = [item.split('|') for item in sentences]\n",
    "    spa_tar = np.array(sentences, dtype=object)\n",
    "\n",
    "# Extract Spanish and Tarahumara sentences from corpus\n",
    "spa = spa_tar[:, 0]\n",
    "tar = spa_tar[:, 1]\n",
    "\n",
    "# Remove unnecessary whitespaces\n",
    "spa = np.array([s.strip() for s in spa])\n",
    "tar = np.array([s.strip() for s in tar])\n",
    "\n",
    "# Remove punctuation and lowercase\n",
    "spa = np.array([s.translate(str.maketrans('', '', string.punctuation + \"¿¡\")).lower() for s in spa])\n",
    "tar = np.array([s.translate(str.maketrans('', '', string.punctuation.replace(\"'\", \"\") + \"¿¡\")).lower() for s in tar])\n",
    "\n",
    "# Viewing sentence lengths\n",
    "spa_len = [len(s.split()) for s in spa]\n",
    "tar_len = [len(s.split()) for s in tar]\n",
    "\n",
    "print(f'Maximum length in Spanish: {max(spa_len)}')\n",
    "print(f'Maximum length in Tarahumara: {max(tar_len)}')\n",
    "\n",
    "length_df = pd.DataFrame({'Spanish':spa_len, 'Tarahumara':tar_len})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "f20f521a-8f39-4118-9ae5-f29eb9b37c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharey = False, tight_layout = True, figsize = (8, 4))\n",
    "\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "ax[0].hist(length_df['Spanish'], bins = 20)\n",
    "ax[0].set_title('Spanish')\n",
    "ax[0].set_xlabel('Number of words')\n",
    "ax[0].set_ylabel('Number of sentences')\n",
    "ax[1].hist(length_df['Tarahumara'], bins = 20)\n",
    "ax[1].set_title('Tarahumara')\n",
    "ax[1].set_xlabel('Number of words')\n",
    "ax[1].set_ylabel('Number of sentences')\n",
    "#fig.suptitle('Sentence Lengths', fontsize=14)\n",
    "fig.savefig('./images/sentence_lengths_' + CORPUS_NAME + '.png', format = 'png')\n",
    "#fig.savefig('/content/drive/MyDrive/Spanish-Tarahumara-Translator/images/sentence_lengths_' + CORPUS_NAME + '.png', format = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c921ed-6bec-4abc-9d9d-e90a557c443c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "38b74225-135e-4c91-a70c-4b6ddfa723a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMT_Parallel_Corpus:\n",
    "    def __init__(self, filepath = None, problem_type = 'source-target'):\n",
    "        self.filepath = filepath\n",
    "        self.problem_type = problem_type\n",
    "        self.encoder_tokenizer = None\n",
    "        self.decoder_tokenizer = None\n",
    "        self.selection_size = None\n",
    "        self.total_size = None\n",
    "        self.train_set = None\n",
    "        self.validation_set = None\n",
    "        \n",
    "    def text_preprocessing(self, text):\n",
    "\n",
    "        # creating a space between a word and the punctuation following it\n",
    "        # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "        # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "        text = re.sub(r\"([?.¡!,¿])\", r\" \\1 \", text)\n",
    "        text = re.sub(r'[\" \"]+', \" \", text)\n",
    "\n",
    "        # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\") and Spanish special characters\n",
    "        text = re.sub(r\"[^a-zA-Z0-9?.¡!,¿áÁéÉíÍóÓúÚñÑüÜ']+\", \" \", text)\n",
    "\n",
    "        text = text.lower()\n",
    "        text = text.strip()\n",
    "\n",
    "        # adding a start and an end token to the sentence\n",
    "        # so that the model know when to start and stop predicting.\n",
    "        text = \"<SOS> \" + text + \" <EOS>\"\n",
    "        return text\n",
    "\n",
    "    def load_data(self, num_examples):\n",
    "        with open(self.filepath, mode = 'rt', encoding = 'utf-8') as infile:\n",
    "            lines = infile.read()\n",
    "            sentences = lines.strip().split('\\n')\n",
    "            sentences = [item.split('|') for item in sentences]\n",
    "            \n",
    "            self.total_size = len(sentences)\n",
    "            \n",
    "            if self.problem_type == 'source-target':\n",
    "                source = [self.text_preprocessing(source) for source, target, _, _ in sentences[:num_examples]]\n",
    "                target = [self.text_preprocessing(target) for source, target, _, _ in sentences[:num_examples]]\n",
    "            \n",
    "            elif self.problem_type == 'target-source':\n",
    "                source = [self.text_preprocessing(source) for target, source, _, _ in sentences[:num_examples]]\n",
    "                target = [self.text_preprocessing(target) for target, source, _, _ in sentences[:num_examples]]\n",
    "                \n",
    "            else:\n",
    "                print('ERROR:  Unknown problem type!')\n",
    "            \n",
    "            self.selection_size = len(source)\n",
    "\n",
    "            return source, target\n",
    "    \n",
    "    def tokenize(self, text, max_text_length):\n",
    "        \n",
    "        tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
    "        tokenizer.fit_on_texts(text)\n",
    "        tokenizer.word_index['<PAD>'] = 0\n",
    "        sequence_list = tokenizer.texts_to_sequences(text)\n",
    "        \n",
    "        if max_text_length == None:\n",
    "            max_len = max([len(sequence) for sequence in sequence_list])\n",
    "            \n",
    "        else:\n",
    "            max_len = max_text_length\n",
    "\n",
    "        # Pad the sequences to match the longest sequences in the given input\n",
    "        padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequence_list, maxlen = max_len, padding = 'post')\n",
    "\n",
    "        return padded_sequences, tokenizer\n",
    "    \n",
    "    def create_datasets(self, BATCH_SIZE, num_examples = None, max_length = None):\n",
    "        if self.filepath == None:\n",
    "            print('WARNING:  Sets cannot be created.  Variable pathfile not set!')\n",
    "            return None, None, None, None\n",
    "            \n",
    "        else:\n",
    "            input_lang, target_lang = self.load_data(num_examples)\n",
    "            \n",
    "            train_input, val_input, train_target, val_target = train_test_split(input_lang, target_lang, test_size = 0.1, random_state = 100)\n",
    "            self.train_set = pd.DataFrame({'Source':train_input, 'Target':train_target})\n",
    "            self.validation_set = pd.DataFrame({'Source':val_input, 'Target':val_target})\n",
    "        \n",
    "            encoder_sequences, self.encoder_tokenizer = self.tokenize(train_input, max_length)\n",
    "            decoder_sequences, self.decoder_tokenizer = self.tokenize(train_target, max_length)\n",
    "            \n",
    "            # The buffer size must be equal or bigger than the total number of sentence pairs in the dataset\n",
    "            BUFFER_SIZE = len(train_input)\n",
    "\n",
    "            train_dataset = tf.data.Dataset.from_tensor_slices((encoder_sequences, decoder_sequences))\n",
    "            train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)\n",
    "\n",
    "            return train_dataset, self.encoder_tokenizer, self.decoder_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ceadab-1aeb-4521-90bc-407ecd29a8af",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "d09e1ae6-980d-4f23-a7cb-dd6d3ba77a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 80\n",
    "BATCH_SIZE = 16\n",
    "EMBEDDING_DIM = 128\n",
    "UNITS = 256\n",
    "NUM_EXAMPLES = None # None -> consider the whole dataset\n",
    "MAX_LENGTH = 20 # None -> consider the whole length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92076867-9149-448d-947c-a8759fdebc8f",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdeaa32-7687-4a97-9040-c7871d8edc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = NMT_Parallel_Corpus(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "0519dafe-9d04-4d25-8217-2c0b1423cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, tok_enc, tok_dec = corpus.create_datasets(BATCH_SIZE, NUM_EXAMPLES, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "b3323065-88cb-42e1-84b4-e4234e550fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus size: 198\n",
      "Selected corpus size: 198\n"
     ]
    }
   ],
   "source": [
    "print(f'Total corpus size: {corpus.total_size}')\n",
    "print(f'Selected corpus size: {corpus.selection_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f45307e5-b9b1-47b5-ac5a-9054f1d71919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 901 unique input tokens.\n",
      "Found 780 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "# Get the word to index mapping for input language\n",
    "word2idx_inputs = tok_enc.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
    "\n",
    "# Get the word to index mapping for output language\n",
    "word2idx_outputs = tok_dec.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "# Map indexes back into real words so we can view the results\n",
    "idx2word_inputs = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_outputs = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "360faa69-91cb-44b0-9f35-45c02da60bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab_size = len(tok_enc.word_index) + 1\n",
    "target_vocab_size = len(tok_dec.word_index) + 1\n",
    "max_length_input = list(train_dataset.as_numpy_iterator())[0][0].shape[1]\n",
    "max_length_target = list(train_dataset.as_numpy_iterator())[0][1].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c5470-1b9b-4855-9f7b-670f9a3aaa17",
   "metadata": {},
   "source": [
    "# Model Architechture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757f3097-489a-4d6e-a9d6-3a9a304dd048",
   "metadata": {},
   "source": [
    "## Unidirectional Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "23a7d845-7745-42c0-b6f3-3728bb213912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, encoder_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_units = encoder_units\n",
    "        \n",
    "        # The Embedding layer convets token IDs to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, embedding_dim)\n",
    "        \n",
    "        # The LSTM layer processes those vectors sequentially\n",
    "        self.lstm = tf.keras.layers.LSTM(self.encoder_units,\n",
    "                                         return_sequences = True,\n",
    "                                         return_state = True,\n",
    "                                         recurrent_initializer = 'glorot_uniform')\n",
    "    \n",
    "    def call(self, tokens, hidden_state = None):\n",
    "        \n",
    "        # The Embedding layer looks up the embedding for each token\n",
    "        embedding_vector = self.embedding(tokens)\n",
    "        \n",
    "        # None as default causes creation of zero-filled initial state tensors\n",
    "        all_h, h, c = self.lstm(embedding_vector, initial_state = hidden_state)\n",
    "        \n",
    "        # Returns the new sequence and its state\n",
    "        return all_h, h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca11f9-12c1-4cba-b7bb-f355d44c0c0c",
   "metadata": {},
   "source": [
    "## Unidirectional Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "cfa46a55-b005-47f4-8d3a-4c619fc76a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, target_vocab_size, embedding_dim, decoder_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoder_units = decoder_units\n",
    "    \n",
    "        # The Embedding layer convets token IDs to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, embedding_dim)\n",
    "        \n",
    "        # The LSTM keeps track of what's been generated so far\n",
    "        self.lstm = tf.keras.layers.LSTM(self.decoder_units,\n",
    "                                         return_sequences=True,\n",
    "                                         return_state=True,\n",
    "                                         recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "        # Final Dense layer on which softmax will be applied\n",
    "        self.dense = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, tokens, initial_state = None):\n",
    "        \n",
    "        # Lookup the embeddings\n",
    "        embedding_vector = self.embedding(tokens)\n",
    "        \n",
    "        # Process one step with the LSTM\n",
    "        all_h, h, c = self.lstm(embedding_vector, initial_state = initial_state)\n",
    "        \n",
    "        # Generate logit predictions\n",
    "        logits = self.dense(all_h)\n",
    "        \n",
    "        return logits, [h, c]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc287940-c3fc-472f-83e4-22aa6adc8c62",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "c39a93e7-027b-42d6-a070-8845d30d8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'auto')\n",
    "    mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y = 0 else output 1\n",
    "    mask = tf.cast(mask, dtype=tf.int64)\n",
    "    loss = cross_entropy(y_true=real, y_pred=pred, sample_weight = mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955bda3c-13e9-4cb1-99f6-b981742c5048",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "14205fd5-b8e5-4a0d-9902-d0a0f35924cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 2.9511\n",
      "Time taken for 1 epoch 6.8700151443481445 [s]\n",
      "\n",
      "Epoch 2 Loss 2.6955\n",
      "Time taken for 1 epoch 5.9707911014556885 [s]\n",
      "\n",
      "Epoch 3 Loss 2.4942\n",
      "Time taken for 1 epoch 5.7835047245025635 [s]\n",
      "\n",
      "Epoch 4 Loss 2.3352\n",
      "Time taken for 1 epoch 6.133932590484619 [s]\n",
      "\n",
      "Epoch 5 Loss 2.2611\n",
      "Time taken for 1 epoch 5.883735656738281 [s]\n",
      "\n",
      "Epoch 6 Loss 2.1414\n",
      "Time taken for 1 epoch 6.422835826873779 [s]\n",
      "\n",
      "Epoch 7 Loss 2.0363\n",
      "Time taken for 1 epoch 6.117032051086426 [s]\n",
      "\n",
      "Epoch 8 Loss 1.9497\n",
      "Time taken for 1 epoch 6.117987871170044 [s]\n",
      "\n",
      "Epoch 9 Loss 1.8323\n",
      "Time taken for 1 epoch 5.902282476425171 [s]\n",
      "\n",
      "Epoch 10 Loss 1.7738\n",
      "Time taken for 1 epoch 6.023821592330933 [s]\n",
      "\n",
      "Epoch 11 Loss 1.6696\n",
      "Time taken for 1 epoch 5.831003904342651 [s]\n",
      "\n",
      "Epoch 12 Loss 1.5699\n",
      "Time taken for 1 epoch 5.872904539108276 [s]\n",
      "\n",
      "Epoch 13 Loss 1.4843\n",
      "Time taken for 1 epoch 5.8872389793396 [s]\n",
      "\n",
      "Epoch 14 Loss 1.3758\n",
      "Time taken for 1 epoch 5.951881647109985 [s]\n",
      "\n",
      "Epoch 15 Loss 1.3126\n",
      "Time taken for 1 epoch 6.1378326416015625 [s]\n",
      "\n",
      "Epoch 16 Loss 1.2274\n",
      "Time taken for 1 epoch 6.221993446350098 [s]\n",
      "\n",
      "Epoch 17 Loss 1.1540\n",
      "Time taken for 1 epoch 5.899757623672485 [s]\n",
      "\n",
      "Epoch 18 Loss 1.0769\n",
      "Time taken for 1 epoch 6.166000843048096 [s]\n",
      "\n",
      "Epoch 19 Loss 1.0139\n",
      "Time taken for 1 epoch 5.8442466259002686 [s]\n",
      "\n",
      "Epoch 20 Loss 0.9481\n",
      "Time taken for 1 epoch 6.0384509563446045 [s]\n",
      "\n",
      "Epoch 21 Loss 0.8969\n",
      "Time taken for 1 epoch 6.25470757484436 [s]\n",
      "\n",
      "Epoch 22 Loss 0.8512\n",
      "Time taken for 1 epoch 5.638312101364136 [s]\n",
      "\n",
      "Epoch 23 Loss 0.7922\n",
      "Time taken for 1 epoch 5.936848878860474 [s]\n",
      "\n",
      "Epoch 24 Loss 0.7553\n",
      "Time taken for 1 epoch 5.941567420959473 [s]\n",
      "\n",
      "Epoch 25 Loss 0.7132\n",
      "Time taken for 1 epoch 5.896637439727783 [s]\n",
      "\n",
      "Epoch 26 Loss 0.6763\n",
      "Time taken for 1 epoch 6.008456707000732 [s]\n",
      "\n",
      "Epoch 27 Loss 0.6277\n",
      "Time taken for 1 epoch 6.142955780029297 [s]\n",
      "\n",
      "Epoch 28 Loss 0.6051\n",
      "Time taken for 1 epoch 6.456002712249756 [s]\n",
      "\n",
      "Epoch 29 Loss 0.5749\n",
      "Time taken for 1 epoch 5.919544458389282 [s]\n",
      "\n",
      "Epoch 30 Loss 0.5418\n",
      "Time taken for 1 epoch 6.383065938949585 [s]\n",
      "\n",
      "Epoch 31 Loss 0.5214\n",
      "Time taken for 1 epoch 5.94136118888855 [s]\n",
      "\n",
      "Epoch 32 Loss 0.4982\n",
      "Time taken for 1 epoch 6.254452705383301 [s]\n",
      "\n",
      "Epoch 33 Loss 0.4758\n",
      "Time taken for 1 epoch 6.054556608200073 [s]\n",
      "\n",
      "Epoch 34 Loss 0.4516\n",
      "Time taken for 1 epoch 6.092821836471558 [s]\n",
      "\n",
      "Epoch 35 Loss 0.4357\n",
      "Time taken for 1 epoch 6.195709943771362 [s]\n",
      "\n",
      "Epoch 36 Loss 0.4178\n",
      "Time taken for 1 epoch 6.320769548416138 [s]\n",
      "\n",
      "Epoch 37 Loss 0.4031\n",
      "Time taken for 1 epoch 6.305167198181152 [s]\n",
      "\n",
      "Epoch 38 Loss 0.3880\n",
      "Time taken for 1 epoch 6.338135242462158 [s]\n",
      "\n",
      "Epoch 39 Loss 0.3743\n",
      "Time taken for 1 epoch 6.245649814605713 [s]\n",
      "\n",
      "Epoch 40 Loss 0.3619\n",
      "Time taken for 1 epoch 6.390361309051514 [s]\n",
      "\n",
      "Epoch 41 Loss 0.3499\n",
      "Time taken for 1 epoch 6.382394790649414 [s]\n",
      "\n",
      "Epoch 42 Loss 0.3382\n",
      "Time taken for 1 epoch 6.325715065002441 [s]\n",
      "\n",
      "Epoch 43 Loss 0.3261\n",
      "Time taken for 1 epoch 6.307743787765503 [s]\n",
      "\n",
      "Epoch 44 Loss 0.3176\n",
      "Time taken for 1 epoch 6.12834906578064 [s]\n",
      "\n",
      "Epoch 45 Loss 0.3080\n",
      "Time taken for 1 epoch 6.3544440269470215 [s]\n",
      "\n",
      "Epoch 46 Loss 0.2963\n",
      "Time taken for 1 epoch 6.3435869216918945 [s]\n",
      "\n",
      "Epoch 47 Loss 0.2886\n",
      "Time taken for 1 epoch 6.399935483932495 [s]\n",
      "\n",
      "Epoch 48 Loss 0.2796\n",
      "Time taken for 1 epoch 6.4657487869262695 [s]\n",
      "\n",
      "Epoch 49 Loss 0.2735\n",
      "Time taken for 1 epoch 6.264005422592163 [s]\n",
      "\n",
      "Epoch 50 Loss 0.2674\n",
      "Time taken for 1 epoch 6.326227188110352 [s]\n",
      "\n",
      "Epoch 51 Loss 0.2588\n",
      "Time taken for 1 epoch 6.542068243026733 [s]\n",
      "\n",
      "Epoch 52 Loss 0.2532\n",
      "Time taken for 1 epoch 6.395487308502197 [s]\n",
      "\n",
      "Epoch 53 Loss 0.2454\n",
      "Time taken for 1 epoch 6.5482189655303955 [s]\n",
      "\n",
      "Epoch 54 Loss 0.2393\n",
      "Time taken for 1 epoch 6.056212663650513 [s]\n",
      "\n",
      "Epoch 55 Loss 0.2318\n",
      "Time taken for 1 epoch 6.195950746536255 [s]\n",
      "\n",
      "Epoch 56 Loss 0.2280\n",
      "Time taken for 1 epoch 6.2577009201049805 [s]\n",
      "\n",
      "Epoch 57 Loss 0.2246\n",
      "Time taken for 1 epoch 6.01485276222229 [s]\n",
      "\n",
      "Epoch 58 Loss 0.2194\n",
      "Time taken for 1 epoch 6.387603759765625 [s]\n",
      "\n",
      "Epoch 59 Loss 0.2129\n",
      "Time taken for 1 epoch 6.413196086883545 [s]\n",
      "\n",
      "Epoch 60 Loss 0.2069\n",
      "Time taken for 1 epoch 6.4571006298065186 [s]\n",
      "\n",
      "Epoch 61 Loss 0.2007\n",
      "Time taken for 1 epoch 6.600566148757935 [s]\n",
      "\n",
      "Epoch 62 Loss 0.1951\n",
      "Time taken for 1 epoch 6.375643730163574 [s]\n",
      "\n",
      "Epoch 63 Loss 0.1907\n",
      "Time taken for 1 epoch 6.415496826171875 [s]\n",
      "\n",
      "Epoch 64 Loss 0.1858\n",
      "Time taken for 1 epoch 6.499265670776367 [s]\n",
      "\n",
      "Epoch 65 Loss 0.1825\n",
      "Time taken for 1 epoch 6.49348783493042 [s]\n",
      "\n",
      "Epoch 66 Loss 0.1777\n",
      "Time taken for 1 epoch 6.371396780014038 [s]\n",
      "\n",
      "Epoch 67 Loss 0.1745\n",
      "Time taken for 1 epoch 6.403075695037842 [s]\n",
      "\n",
      "Epoch 68 Loss 0.1700\n",
      "Time taken for 1 epoch 6.552513122558594 [s]\n",
      "\n",
      "Epoch 69 Loss 0.1664\n",
      "Time taken for 1 epoch 6.593929767608643 [s]\n",
      "\n",
      "Epoch 70 Loss 0.1636\n",
      "Time taken for 1 epoch 6.496612310409546 [s]\n",
      "\n",
      "Epoch 71 Loss 0.1600\n",
      "Time taken for 1 epoch 6.156388521194458 [s]\n",
      "\n",
      "Epoch 72 Loss 0.1588\n",
      "Time taken for 1 epoch 6.1845479011535645 [s]\n",
      "\n",
      "Epoch 73 Loss 0.1566\n",
      "Time taken for 1 epoch 6.316168785095215 [s]\n",
      "\n",
      "Epoch 74 Loss 0.1522\n",
      "Time taken for 1 epoch 6.1954896450042725 [s]\n",
      "\n",
      "Epoch 75 Loss 0.1490\n",
      "Time taken for 1 epoch 6.629501819610596 [s]\n",
      "\n",
      "Epoch 76 Loss 0.1441\n",
      "Time taken for 1 epoch 11.800790548324585 [s]\n",
      "\n",
      "Epoch 77 Loss 0.1422\n",
      "Time taken for 1 epoch 6.694502592086792 [s]\n",
      "\n",
      "Epoch 78 Loss 0.1382\n",
      "Time taken for 1 epoch 6.4128193855285645 [s]\n",
      "\n",
      "Epoch 79 Loss 0.1360\n",
      "Time taken for 1 epoch 6.032645225524902 [s]\n",
      "\n",
      "Epoch 80 Loss 0.1328\n",
      "Time taken for 1 epoch 6.412532806396484 [s]\n",
      "\n",
      "Total training time: 8.399970873196919 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(input_vocab_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\n",
    "decoder = Decoder(target_vocab_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.005, beta_1 = 0.9, beta_2 = 0.999, decay = 0.01)\n",
    "loss_history = []\n",
    "\n",
    "# Create a checkpoint object to save the model\n",
    "checkpoint_dir = './training_ckpt_seq2seq'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(train_dataset):\n",
    "        \n",
    "        loss = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            enc_output, enc_h, enc_c = encoder(inp)\n",
    "            dec_state = [enc_h, enc_c]\n",
    "            dec_input = tf.expand_dims([word2idx_outputs['<sos>']] * BATCH_SIZE, 1)\n",
    "            \n",
    "            for t in range(1, targ.shape[1]):\n",
    "                \n",
    "                # Passing enc_output to the decoder\n",
    "                logits, dec_state = decoder(dec_input, dec_state)\n",
    "                \n",
    "                # Calculate cumulative loss\n",
    "                loss += loss_function(targ[:, t], logits)\n",
    "                \n",
    "                # Apply teacher forcing:  feeding the target as the next input\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "            \n",
    "        total_loss += (loss / int(targ.shape[1]))\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "    loss_history.append(total_loss / len(train_dataset))\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / len(train_dataset)))\n",
    "    print('Time taken for 1 epoch {} [s]\\n'.format(time.time() - start))\n",
    "print(f'Total training time: {(time.time() - start_time)/60} minutes\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "05699f3c-8ef6-4866-ad46-605a91e6f9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, tight_layout = True, figsize = (6, 4))\n",
    "plt.plot(loss_history)\n",
    "plt.legend(['Training'])\n",
    "plt.title(CORPUS_NAME + ' Corpus')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "if MAX_LENGTH == None:\n",
    "    length = 'max'\n",
    "else:\n",
    "    length = str(MAX_LENGTH)\n",
    "\n",
    "fig.savefig('./images/' + CORPUS_NAME + '_loss_len_' + length + '.png', format = 'png')\n",
    "#fig.savefig('/content/drive/MyDrive/Spanish-Tarahumara-Translator/images/' + CORPUS_NAME + '_loss_len_' + length + '.png', format = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9ac3aa-3f5d-447b-ab43-031e373deca9",
   "metadata": {},
   "source": [
    "# Prediction Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "c2f44da8-468d-4d19-848c-98925df0a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_text, encoder, decoder, input_max_len, output_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs):\n",
    "    if input_text is None:\n",
    "        input_text = input_data[np.random.choice(len(input_data))]\n",
    "        \n",
    "    # Tokenize the input sequence\n",
    "    input_seq = tokenizer_inputs.texts_to_sequences([input_text])\n",
    "    \n",
    "    # Pad the sentence\n",
    "    input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=input_max_len, padding='post')\n",
    "    \n",
    "    # Calculate encoder output\n",
    "    en_outputs = encoder(tf.constant(input_seq))\n",
    "    \n",
    "    # Create the decoder input (<SOS> token)\n",
    "    de_input = tf.constant([[word2idx_outputs['<sos>']]])\n",
    "    \n",
    "    # Set the decoder states to the encoder vector or encoder hidden state\n",
    "    de_state = en_outputs[1:]\n",
    "    \n",
    "    out_words = []\n",
    "    while True:\n",
    "        # Decode and get the output probabilities\n",
    "        de_output, de_state = decoder(de_input, de_state)\n",
    "        \n",
    "        # Select the word with the highest probability\n",
    "        de_input = tf.argmax(de_output, -1)\n",
    "        \n",
    "        # Append the word to the predicted output\n",
    "        out_words.append(idx2word_outputs[de_input.numpy()[0][0]])\n",
    "        \n",
    "        # Finish when <EOS> token is found or the max length is reached\n",
    "        if out_words[-1] == '<eos>' or len(out_words) >= output_max_len:\n",
    "            break\n",
    "\n",
    "    translation = ' '.join(out_words)\n",
    "    return translation, out_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd1513-dea4-464d-a69c-31ed04fdc227",
   "metadata": {},
   "source": [
    "## Evaluating Predictions with Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "be7b1ae6-9d1a-4685-8cc4-18689541518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = corpus.train_set['Source'].apply(lambda x : predict(x, encoder, decoder, max_length_input, max_length_target, tok_enc, word2idx_outputs, idx2word_outputs)[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "60ac29ea-3d83-46d6-9ec3-bfeb9471cc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; ¿ dónde vive usted ? &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; ¿ comi bité mujé ? &lt;EOS&gt;</td>\n",
       "      <td>¿ mujé comi simí ? &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; a lo que canta un pájaro . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; mapu a'lí ta nalépua chulukí jíti . &lt;EOS&gt;</td>\n",
       "      <td>mapu a'lí ta nalépua chulukí jíti . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; está haciendo mucho frío . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; hue ruluá . &lt;EOS&gt;</td>\n",
       "      <td>hue ratáami rayena . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; tus abuelos maternos . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; kému apalócha a'lí kému u'sú . &lt;EOS&gt;</td>\n",
       "      <td>kému apalócha a'lí kému u'sú . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; el tarahumar con el sonido de la piel despierta a sus padres &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; ralámuli wichí anéala kiti busurébi e'wénuala &lt;EOS&gt;</td>\n",
       "      <td>ralámuli wichí anéala kiti busurébi e'wénuala &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     Source  \\\n",
       "0                                          <SOS> ¿ dónde vive usted ? <EOS>   \n",
       "1                                    <SOS> a lo que canta un pájaro . <EOS>   \n",
       "2                                    <SOS> está haciendo mucho frío . <EOS>   \n",
       "3                                        <SOS> tus abuelos maternos . <EOS>   \n",
       "4  <SOS> el tarahumar con el sonido de la piel despierta a sus padres <EOS>   \n",
       "\n",
       "                                                      Target  \\\n",
       "0                             <SOS> ¿ comi bité mujé ? <EOS>   \n",
       "1            <SOS> mapu a'lí ta nalépua chulukí jíti . <EOS>   \n",
       "2                                    <SOS> hue ruluá . <EOS>   \n",
       "3                 <SOS> kému apalócha a'lí kému u'sú . <EOS>   \n",
       "4  <SOS> ralámuli wichí anéala kiti busurébi e'wénuala <EOS>   \n",
       "\n",
       "                                           Predictions  \n",
       "0                             ¿ mujé comi simí ? <eos>  \n",
       "1            mapu a'lí ta nalépua chulukí jíti . <eos>  \n",
       "2                           hue ratáami rayena . <eos>  \n",
       "3                 kému apalócha a'lí kému u'sú . <eos>  \n",
       "4  ralámuli wichí anéala kiti busurébi e'wénuala <eos>  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "train_df = corpus.train_set\n",
    "train_df['Predictions'] = predictions\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de74cf0e-a0a7-43a5-9667-3d0730f90a96",
   "metadata": {},
   "source": [
    "### BLEU Scores Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "9d84af9a-412e-430f-a67d-7b76eb169892",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_bleu = corpus.train_set['Source'].apply(lambda x : predict(x,encoder, decoder, max_length_input, max_length_target, tok_enc, word2idx_outputs, idx2word_outputs)[1]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e779c9c-2b91-472b-b488-d8801d3053b9",
   "metadata": {},
   "source": [
    "#### Translation and Target Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "dc205676-6215-44ae-9343-f081d962cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction output preprocessing for calculating BLEU score\n",
    "for i in range(len(candidates_bleu)):\n",
    "    # Remove duplicate elements like commas\n",
    "    candidates_bleu[i] = list(dict.fromkeys(candidates_bleu[i]))\n",
    "    # Remove <EOS> token\n",
    "    if '<eos>' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('<eos>')\n",
    "    # Remove special punctuation characters\n",
    "    if '.' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('.')\n",
    "    if ',' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove(',')\n",
    "    if '!' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('!')\n",
    "    if '¡' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('¡')\n",
    "    if '?' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('?')\n",
    "    if '¿' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('¿')\n",
    "\n",
    "# Target preprocessing for calculating BLEU score\n",
    "references_bleu = train_df['Target'].to_list()\n",
    "\n",
    "for i in range(len(references_bleu)):\n",
    "    references_bleu[i] = references_bleu[i].split()\n",
    "    # Remove duplicate elements like commas\n",
    "    references_bleu[i] = list(dict.fromkeys(references_bleu[i]))\n",
    "    # Remove <SOS> token\n",
    "    references_bleu[i].remove('<SOS>')\n",
    "    # Remove <EOS> token\n",
    "    references_bleu[i].remove('<EOS>')\n",
    "    # Remove special punctuation characters\n",
    "    if '.' in references_bleu[i]:\n",
    "        references_bleu[i].remove('.')\n",
    "    if ',' in references_bleu[i]:\n",
    "        references_bleu[i].remove(',')\n",
    "    if '!' in references_bleu[i]:\n",
    "        references_bleu[i].remove('!')\n",
    "    if '¡' in references_bleu[i]:\n",
    "        references_bleu[i].remove('¡')\n",
    "    if '?' in references_bleu[i]:\n",
    "        references_bleu[i].remove('?')\n",
    "    if '¿' in references_bleu[i]:\n",
    "        references_bleu[i].remove('¿')\n",
    "\n",
    "references_bleu_train = list()\n",
    "for i in range(len(references_bleu)):\n",
    "    references_bleu_train.append(list())\n",
    "    references_bleu_train[i].append(references_bleu[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8a9ed-ad75-4b6b-994f-c96252f37811",
   "metadata": {},
   "source": [
    "* **Corpus BLEU Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b6efb439-81d6-4e6a-bb61-e145539d5194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU-1 score: 0.5716240111784193\n",
      "Corpus BLEU-4 score: 0.46609440809000097\n"
     ]
    }
   ],
   "source": [
    "score = corpus_bleu(references_bleu_train, candidates_bleu, weights = (1,0,0,0))\n",
    "print(f'Corpus BLEU-1 score: {score}')\n",
    "score = corpus_bleu(references_bleu_train, candidates_bleu)\n",
    "print(f'Corpus BLEU-4 score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20243d0f-21cc-4188-8a32-cb5b116ca3c3",
   "metadata": {},
   "source": [
    "* **Sentence BLEU Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "656e5d9e-328a-4b63-a6e1-6e4fcebc39af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>BLEU-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; ¿ dónde vive usted ? &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; ¿ comi bité mujé ? &lt;EOS&gt;</td>\n",
       "      <td>¿ mujé comi simí ? &lt;eos&gt;</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.646211e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; a lo que canta un pájaro . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; mapu a'lí ta nalépua chulukí jíti . &lt;EOS&gt;</td>\n",
       "      <td>mapu a'lí ta nalépua chulukí jíti . &lt;eos&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; está haciendo mucho frío . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; hue ruluá . &lt;EOS&gt;</td>\n",
       "      <td>hue ratáami rayena . &lt;eos&gt;</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.384293e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; tus abuelos maternos . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; kému apalócha a'lí kému u'sú . &lt;EOS&gt;</td>\n",
       "      <td>kému apalócha a'lí kému u'sú . &lt;eos&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; el tarahumar con el sonido de la piel despierta a sus padres &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; ralámuli wichí anéala kiti busurébi e'wénuala &lt;EOS&gt;</td>\n",
       "      <td>ralámuli wichí anéala kiti busurébi e'wénuala &lt;eos&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     Source  \\\n",
       "0                                          <SOS> ¿ dónde vive usted ? <EOS>   \n",
       "1                                    <SOS> a lo que canta un pájaro . <EOS>   \n",
       "2                                    <SOS> está haciendo mucho frío . <EOS>   \n",
       "3                                        <SOS> tus abuelos maternos . <EOS>   \n",
       "4  <SOS> el tarahumar con el sonido de la piel despierta a sus padres <EOS>   \n",
       "\n",
       "                                                      Target  \\\n",
       "0                             <SOS> ¿ comi bité mujé ? <EOS>   \n",
       "1            <SOS> mapu a'lí ta nalépua chulukí jíti . <EOS>   \n",
       "2                                    <SOS> hue ruluá . <EOS>   \n",
       "3                 <SOS> kému apalócha a'lí kému u'sú . <EOS>   \n",
       "4  <SOS> ralámuli wichí anéala kiti busurébi e'wénuala <EOS>   \n",
       "\n",
       "                                           Predictions    BLEU-1  \\\n",
       "0                             ¿ mujé comi simí ? <eos>  0.666667   \n",
       "1            mapu a'lí ta nalépua chulukí jíti . <eos>  1.000000   \n",
       "2                           hue ratáami rayena . <eos>  0.333333   \n",
       "3                 kému apalócha a'lí kému u'sú . <eos>  1.000000   \n",
       "4  ralámuli wichí anéala kiti busurébi e'wénuala <eos>  1.000000   \n",
       "\n",
       "          BLEU-4  \n",
       "0  1.646211e-231  \n",
       "1   1.000000e+00  \n",
       "2  1.384293e-231  \n",
       "3   1.000000e+00  \n",
       "4   1.000000e+00  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu_scores = []\n",
    "for i in range(len(references_bleu)):\n",
    "    sentence_bleu_scores.append(sentence_bleu(references_bleu_train[i], candidates_bleu[i], weights = (1,0,0,0)))\n",
    "train_df['BLEU-1'] = sentence_bleu_scores\n",
    "\n",
    "sentence_bleu_scores = []\n",
    "for i in range(len(references_bleu)):\n",
    "    sentence_bleu_scores.append(sentence_bleu(references_bleu_train[i], candidates_bleu[i])) \n",
    "train_df['BLEU-4'] = sentence_bleu_scores\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "6f80ad9e-afa0-4dbc-afca-202dacd2eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_excel('./results/train_' + CORPUS_NAME + '_len_' + length + '.xlsx')\n",
    "#train_df.to_excel('/content/drive/MyDrive/Spanish-Tarahumara-Translator/results/train_' + CORPUS_NAME + '_len_' + length + '.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad8e525-916a-4979-9729-f1d88f10ba39",
   "metadata": {},
   "source": [
    "## Predictions with Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "e6ebd2d3-d17c-49b9-81f9-575e7571d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = corpus.validation_set['Source'].apply(lambda x : predict(x, encoder, decoder, max_length_input, max_length_target, tok_enc, word2idx_outputs, idx2word_outputs)[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "aa1163f8-b2ae-49a0-86e3-e3b3f0999e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; artículo 2o . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; osirúa'mi 2 . &lt;EOS&gt;</td>\n",
       "      <td>osirúa'mi 9 . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; ya haz nacer al maíz y a las demás plantas . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; má ochébi suunú a'lí jalé chó reyawi . &lt;EOS&gt;</td>\n",
       "      <td>'échi kó 'á tibúma , natuíka nocháa'mi kíti kó a'lá kánílika retemáka perélima . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; para que comience a nacer la hierba &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; mapuliká reyáwi chotáma a'wiyá &lt;EOS&gt;</td>\n",
       "      <td>mapuliká suunú chotáma a'wiyá . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; despiertan alegres al escuchar el eco . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; népi busuré kaníla kipúu rampóli kebáala . &lt;EOS&gt;</td>\n",
       "      <td>mapu mu rajáa lé okólale &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; fue así como fueron creados los rarámuri y los chabochi &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; echiriká iwítali rarámuri alí chabochi &lt;EOS&gt;</td>\n",
       "      <td>népi iwéame kebári sikóchi , resochí , a'lí bakóchi &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Source  \\\n",
       "0                                            <SOS> artículo 2o . <EOS>   \n",
       "1             <SOS> ya haz nacer al maíz y a las demás plantas . <EOS>   \n",
       "2                      <SOS> para que comience a nacer la hierba <EOS>   \n",
       "3                  <SOS> despiertan alegres al escuchar el eco . <EOS>   \n",
       "4  <SOS> fue así como fueron creados los rarámuri y los chabochi <EOS>   \n",
       "\n",
       "                                                   Target  \\\n",
       "0                               <SOS> osirúa'mi 2 . <EOS>   \n",
       "1      <SOS> má ochébi suunú a'lí jalé chó reyawi . <EOS>   \n",
       "2              <SOS> mapuliká reyáwi chotáma a'wiyá <EOS>   \n",
       "3  <SOS> népi busuré kaníla kipúu rampóli kebáala . <EOS>   \n",
       "4      <SOS> echiriká iwítali rarámuri alí chabochi <EOS>   \n",
       "\n",
       "                                                                              Predictions  \n",
       "0                                                                     osirúa'mi 9 . <eos>  \n",
       "1  'échi kó 'á tibúma , natuíka nocháa'mi kíti kó a'lá kánílika retemáka perélima . <eos>  \n",
       "2                                                   mapuliká suunú chotáma a'wiyá . <eos>  \n",
       "3                                                          mapu mu rajáa lé okólale <eos>  \n",
       "4                               népi iwéame kebári sikóchi , resochí , a'lí bakóchi <eos>  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = corpus.validation_set\n",
    "validation_df['Predictions'] = predictions\n",
    "validation_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb94de-5989-41e6-a9d3-a1c410df68ab",
   "metadata": {},
   "source": [
    "### BLEU Score (Validation Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "eefd12da-fc9b-40e8-8f4f-0607a0c540c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_bleu = corpus.validation_set['Source'].apply(lambda x : predict(x, encoder, decoder, max_length_input, max_length_target, tok_enc, word2idx_outputs, idx2word_outputs)[1]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad22ea-bb99-4bea-b596-bf9b01c33940",
   "metadata": {},
   "source": [
    "#### Translation and Target Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "3c8ea860-2ea4-46a3-a2b5-f647b7b20e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction output preprocessing for calculating BLEU score\n",
    "for i in range(len(candidates_bleu)):\n",
    "    # Remove duplicate elements like commas\n",
    "    candidates_bleu[i] = list(dict.fromkeys(candidates_bleu[i]))\n",
    "    # Remove <EOS> token\n",
    "    if '<eos>' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('<eos>')\n",
    "    # Remove special punctuation characters\n",
    "    if '.' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('.')\n",
    "    if ',' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove(',')\n",
    "    if '!' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('!')\n",
    "    if '¡' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('¡')\n",
    "    if '?' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('?')\n",
    "    if '¿' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('¿')\n",
    "        \n",
    "# Target preprocessing for calculating BLEU score\n",
    "references_bleu = validation_df['Target'].to_list()\n",
    "\n",
    "for i in range(len(references_bleu)):\n",
    "    references_bleu[i] = references_bleu[i].split()\n",
    "    # Remove duplicate elements like commas\n",
    "    references_bleu[i] = list(dict.fromkeys(references_bleu[i]))\n",
    "    # Remove <SOS> token\n",
    "    references_bleu[i].remove('<SOS>')\n",
    "    # Remove <EOS> token\n",
    "    references_bleu[i].remove('<EOS>')\n",
    "    # Remove special punctuation characters\n",
    "    if '.' in references_bleu[i]:\n",
    "        references_bleu[i].remove('.')\n",
    "    if ',' in references_bleu[i]:\n",
    "        references_bleu[i].remove(',')\n",
    "    if '!' in references_bleu[i]:\n",
    "        references_bleu[i].remove('!')\n",
    "    if '¡' in references_bleu[i]:\n",
    "        references_bleu[i].remove('¡')\n",
    "    if '?' in references_bleu[i]:\n",
    "        references_bleu[i].remove('?')\n",
    "    if '¿' in references_bleu[i]:\n",
    "        references_bleu[i].remove('¿')\n",
    "\n",
    "references_bleu_validation = list()\n",
    "for i in range(len(references_bleu)):\n",
    "    references_bleu_validation.append(list())\n",
    "    references_bleu_validation[i].append(references_bleu[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b89422-6521-4aa0-a985-ac293b5a161e",
   "metadata": {},
   "source": [
    "* **Corpus BLEU Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "74a13195-9403-41da-8f33-41a1c1c5beec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU-1 score: 0.10655602356699787\n",
      "Corpus BLEU-4 score: 2.0844895083624263e-155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "score = corpus_bleu(references_bleu_validation, candidates_bleu, weights = (1,0,0,0))\n",
    "print(f'Corpus BLEU-1 score: {score}')\n",
    "score = corpus_bleu(references_bleu_validation, candidates_bleu)\n",
    "print(f'Corpus BLEU-4 score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048f1b3f-0507-4eb8-a81c-8bac07b2cd80",
   "metadata": {},
   "source": [
    "* **Sentence BLEU Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "2b804cf3-e0e3-4487-bc2e-fffa367f8a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>BLEU-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; artículo 2o . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; osirúa'mi 2 . &lt;EOS&gt;</td>\n",
       "      <td>osirúa'mi 9 . &lt;eos&gt;</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.531972e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; ya haz nacer al maíz y a las demás plantas . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; má ochébi suunú a'lí jalé chó reyawi . &lt;EOS&gt;</td>\n",
       "      <td>'échi kó 'á tibúma , natuíka nocháa'mi kíti kó a'lá kánílika retemáka perélima . &lt;eos&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; para que comience a nacer la hierba &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; mapuliká reyáwi chotáma a'wiyá &lt;EOS&gt;</td>\n",
       "      <td>mapuliká suunú chotáma a'wiyá . &lt;eos&gt;</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.054769e-154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; despiertan alegres al escuchar el eco . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; népi busuré kaníla kipúu rampóli kebáala . &lt;EOS&gt;</td>\n",
       "      <td>mapu mu rajáa lé okólale &lt;eos&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; fue así como fueron creados los rarámuri y los chabochi &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; echiriká iwítali rarámuri alí chabochi &lt;EOS&gt;</td>\n",
       "      <td>népi iwéame kebári sikóchi , resochí , a'lí bakóchi &lt;eos&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Source  \\\n",
       "0                                            <SOS> artículo 2o . <EOS>   \n",
       "1             <SOS> ya haz nacer al maíz y a las demás plantas . <EOS>   \n",
       "2                      <SOS> para que comience a nacer la hierba <EOS>   \n",
       "3                  <SOS> despiertan alegres al escuchar el eco . <EOS>   \n",
       "4  <SOS> fue así como fueron creados los rarámuri y los chabochi <EOS>   \n",
       "\n",
       "                                                   Target  \\\n",
       "0                               <SOS> osirúa'mi 2 . <EOS>   \n",
       "1      <SOS> má ochébi suunú a'lí jalé chó reyawi . <EOS>   \n",
       "2              <SOS> mapuliká reyáwi chotáma a'wiyá <EOS>   \n",
       "3  <SOS> népi busuré kaníla kipúu rampóli kebáala . <EOS>   \n",
       "4      <SOS> echiriká iwítali rarámuri alí chabochi <EOS>   \n",
       "\n",
       "                                                                              Predictions  \\\n",
       "0                                                                     osirúa'mi 9 . <eos>   \n",
       "1  'échi kó 'á tibúma , natuíka nocháa'mi kíti kó a'lá kánílika retemáka perélima . <eos>   \n",
       "2                                                   mapuliká suunú chotáma a'wiyá . <eos>   \n",
       "3                                                          mapu mu rajáa lé okólale <eos>   \n",
       "4                               népi iwéame kebári sikóchi , resochí , a'lí bakóchi <eos>   \n",
       "\n",
       "   BLEU-1         BLEU-4  \n",
       "0    0.50  1.531972e-231  \n",
       "1    0.00   0.000000e+00  \n",
       "2    0.75  1.054769e-154  \n",
       "3    0.00   0.000000e+00  \n",
       "4    0.00   0.000000e+00  "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu_scores = []\n",
    "for i in range(len(references_bleu)):\n",
    "    sentence_bleu_scores.append(sentence_bleu(references_bleu_validation[i], candidates_bleu[i], weights = (1,0,0,0)))\n",
    "validation_df['BLEU-1'] = sentence_bleu_scores\n",
    "\n",
    "sentence_bleu_scores = []\n",
    "for i in range(len(references_bleu)):\n",
    "    sentence_bleu_scores.append(sentence_bleu(references_bleu_validation[i], candidates_bleu[i]))\n",
    "validation_df['BLEU-4'] = sentence_bleu_scores\n",
    "validation_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "58215155-c441-4c17-8472-799aade5c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.to_excel('./results/val_' + CORPUS_NAME + '_len_' + length + '.xlsx')\n",
    "#validation_df.to_excel('/content/drive/MyDrive/Spanish-Tarahumara-Translator/results/val_' + CORPUS_NAME + '_len_' + length + '.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de29b6d7-c6e2-4453-a0a0-e94b63cf1dea",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<li><a href=\"https://aclanthology.org/D14-1179\">Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation</a> (Cho et al., EMNLP 2014)</li>\n",
    "\n",
    "<li><a href=\"https://arxiv.org/abs/1409.0473\">Neural Machine Translation by Jointly Learning to Align and Translate</a> (Bahdanau et al., ICLR 2015)</li>\n",
    "\n",
    "<li><a href=\"https://arxiv.org/abs/1809.06662\">Bidirectional Attentional Encoder-Decoder Model and Bidirectional Beam Search for Abstractive Summarization</a> (Al-Sabahi et al., arXiv 2018)</li>\n",
    "\n",
    "<li><a href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/nmt_with_attention.ipynb\">TensorFlow Tutorial:  Neural Machine Translation with Attention</a> (GitHub Repository)</li>\n",
    "\n",
    "<li><a href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb\">TensorFlow Tutorial:  Text Generation with an RNN</a> (GitHub Repository)</li>\n",
    "\n",
    "<li><a href=\"https://colab.research.google.com/github/tensorflow/addons/blob/master/docs/tutorials/networks_seq2seq_nmt.ipynb\">TensorFlow Addons Networks:  Sequence-to-Sequence NMT with Attention Mechanism</a> (GitHub Repository)</li>\n",
    "\n",
    "<li><a href=\"https://github.com/edumunozsala/NMT-encoder-decoder-Attention\">NMT-encoder-decoder-Attention</a> (GitHub Repository)</li>\n",
    "\n",
    "<li><a href=\"https://www.kaggle.com/code/rizdelhi/end-to-end-nlp-4-attention-and-transformer\">end-to-end-nlp-4-attention-and-transformer</a> (Kaggle Notebook)</li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMT",
   "language": "python",
   "name": "smt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
