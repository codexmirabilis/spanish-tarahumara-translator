{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "389e430f-0675-4d1d-9388-d88f7b674ad3",
   "metadata": {},
   "source": [
    "<div class=\"infotext\" style='padding:0.1em; color:#000000'>\n",
    "<span>\n",
    "<p style='margin-top:1em; text-align:center'><font size=\"10\"><b>Spanish-to-Tarahumara Translation</b></font></p>\n",
    "    <p style='margin-top:1em; text-align:center'><font size=\"5\"><b>Bidirectional LSTM Encoder - Bidirectional LSTM Decoder with Attention Layer</b></font></p>\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8caf8e32-c494-4d4f-aa56-5f8c51ff7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spanish-Tarahumara-Translator:  Bidirectional LSTM Encoder - Bidirectional LSTM Decoder with Attention Layer\n",
    "# Copyright (C) 2022  Eduardo Aguilar Moreno\n",
    "\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb78928-1279-4495-b68c-fc2e04b8033a",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926bc360-855a-4168-99a6-324276781193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e11bc49b-20c5-493f-b175-ad6b17970a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62529de1-20a5-4e26-b484-0b227eb01437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e4ca75-b3f0-499f-b905-94f98281d0d9",
   "metadata": {},
   "source": [
    "# Viewing Sentence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0896cb4-1f69-4452-82c5-5b688bcb95dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length in Spanish: 83\n",
      "Maximum length in Tarahumara: 103\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME = \"./corpora/rarámuri.txt\"\n",
    "#FILE_NAME = \"./corpora/americasnlp2021.txt\"\n",
    "#FILE_NAME = \"/content/drive/MyDrive/Spanish-Tarahumara-Translator/corpora/rarámuri.txt\"\n",
    "#FILE_NAME = \"/content/drive/MyDrive/Spanish-Tarahumara-Translator/corpora/americasnlp2021.txt\"\n",
    "\n",
    "CORPUS_NAME = FILE_NAME.split(sep='/')[-1].split(sep='.')[0]\n",
    "\n",
    "with open(FILE_NAME, mode = 'rt', encoding = 'utf-8') as infile:\n",
    "    lines = infile.read()\n",
    "    sentences = lines.strip().split('\\n')\n",
    "    sentences = [item.split('|') for item in sentences]\n",
    "    spa_tar = np.array(sentences, dtype=object)\n",
    "\n",
    "# Extract Spanish and Tarahumara sentences from corpus\n",
    "spa = spa_tar[:, 0]\n",
    "tar = spa_tar[:, 1]\n",
    "\n",
    "# Remove unnecessary whitespaces\n",
    "spa = np.array([s.strip() for s in spa])\n",
    "tar = np.array([s.strip() for s in tar])\n",
    "\n",
    "# Remove punctuation and lowercase\n",
    "spa = np.array([s.translate(str.maketrans('', '', string.punctuation + \"¿¡\")).lower() for s in spa])\n",
    "tar = np.array([s.translate(str.maketrans('', '', string.punctuation.replace(\"'\", \"\") + \"¿¡\")).lower() for s in tar])\n",
    "\n",
    "# Viewing sentence lengths\n",
    "spa_len = [len(s.split()) for s in spa]\n",
    "tar_len = [len(s.split()) for s in tar]\n",
    "\n",
    "print(f'Maximum length in Spanish: {max(spa_len)}')\n",
    "print(f'Maximum length in Tarahumara: {max(tar_len)}')\n",
    "\n",
    "length_df = pd.DataFrame({'Spanish':spa_len, 'Tarahumara':tar_len})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0a7fdb-0c6b-419b-931a-d7d7cfd51e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharey = False, tight_layout = True, figsize = (8, 4))\n",
    "\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "ax[0].hist(length_df['Spanish'], bins = 20)\n",
    "ax[0].set_title('Spanish')\n",
    "ax[0].set_xlabel('Number of words')\n",
    "ax[0].set_ylabel('Number of sentences')\n",
    "ax[1].hist(length_df['Tarahumara'], bins = 20)\n",
    "ax[1].set_title('Tarahumara')\n",
    "ax[1].set_xlabel('Number of words')\n",
    "ax[1].set_ylabel('Number of sentences')\n",
    "#fig.suptitle('Sentence Lengths', fontsize=14)\n",
    "fig.savefig('./images/sentence_lengths_' + CORPUS_NAME + '.png', format = 'png')\n",
    "#fig.savefig('/content/drive/MyDrive/Spanish-Tarahumara-Translator/images/sentence_lengths_' + CORPUS_NAME + '.png', format = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c921ed-6bec-4abc-9d9d-e90a557c443c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b74225-135e-4c91-a70c-4b6ddfa723a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMT_Parallel_Corpus:\n",
    "    def __init__(self, filepath = None, problem_type = 'source-target'):\n",
    "        self.filepath = filepath\n",
    "        self.problem_type = problem_type\n",
    "        self.encoder_tokenizer = None\n",
    "        self.decoder_tokenizer = None\n",
    "        self.selection_size = None\n",
    "        self.total_size = None\n",
    "        self.train_set = None\n",
    "        self.validation_set = None\n",
    "        \n",
    "    def text_preprocessing(self, text):\n",
    "\n",
    "        # creating a space between a word and the punctuation following it\n",
    "        # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "        # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "        text = re.sub(r\"([?.¡!,¿])\", r\" \\1 \", text)\n",
    "        text = re.sub(r'[\" \"]+', \" \", text)\n",
    "\n",
    "        # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\") and Spanish special characters\n",
    "        text = re.sub(r\"[^a-zA-Z0-9?.¡!,¿áÁéÉíÍóÓúÚñÑüÜ']+\", \" \", text)\n",
    "\n",
    "        text = text.lower()\n",
    "        text = text.strip()\n",
    "\n",
    "        # adding a start and an end token to the sentence\n",
    "        # so that the model know when to start and stop predicting.\n",
    "        text = \"<SOS> \" + text + \" <EOS>\"\n",
    "        return text\n",
    "\n",
    "    def load_data(self, num_examples):\n",
    "        with open(self.filepath, mode = 'rt', encoding = 'utf-8') as infile:\n",
    "            lines = infile.read()\n",
    "            sentences = lines.strip().split('\\n')\n",
    "            sentences = [item.split('|') for item in sentences]\n",
    "            \n",
    "            self.total_size = len(sentences)\n",
    "            \n",
    "            if self.problem_type == 'source-target':\n",
    "                source = [self.text_preprocessing(source) for source, target, _, _ in sentences[:num_examples]]\n",
    "                target = [self.text_preprocessing(target) for source, target, _, _ in sentences[:num_examples]]\n",
    "            \n",
    "            elif self.problem_type == 'target-source':\n",
    "                source = [self.text_preprocessing(source) for target, source, _, _ in sentences[:num_examples]]\n",
    "                target = [self.text_preprocessing(target) for target, source, _, _ in sentences[:num_examples]]\n",
    "                \n",
    "            else:\n",
    "                print('ERROR:  Unknown problem type!')\n",
    "            \n",
    "            self.selection_size = len(source)\n",
    "\n",
    "            return source, target\n",
    "    \n",
    "    def tokenize(self, text, max_text_length):\n",
    "        \n",
    "        tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
    "        tokenizer.fit_on_texts(text)\n",
    "        tokenizer.word_index['<PAD>'] = 0\n",
    "        sequence_list = tokenizer.texts_to_sequences(text)\n",
    "        \n",
    "        if max_text_length == None:\n",
    "            max_len = max([len(sequence) for sequence in sequence_list])\n",
    "            \n",
    "        else:\n",
    "            max_len = max_text_length\n",
    "\n",
    "        # Pad the sequences to match the longest sequences in the given input\n",
    "        padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequence_list, maxlen = max_len, padding = 'post')\n",
    "\n",
    "        return padded_sequences, tokenizer\n",
    "    \n",
    "    def create_datasets(self, BATCH_SIZE, num_examples = None, max_length = None):\n",
    "        if self.filepath == None:\n",
    "            print('WARNING:  Sets cannot be created.  Variable pathfile not set!')\n",
    "            return None, None, None, None\n",
    "            \n",
    "        else:\n",
    "            input_lang, target_lang = self.load_data(num_examples)\n",
    "            \n",
    "            train_input, val_input, train_target, val_target = train_test_split(input_lang, target_lang, test_size = 0.1, random_state = 100)\n",
    "            self.train_set = pd.DataFrame({'Source':train_input, 'Target':train_target})\n",
    "            self.validation_set = pd.DataFrame({'Source':val_input, 'Target':val_target})\n",
    "        \n",
    "            encoder_sequences, self.encoder_tokenizer = self.tokenize(train_input, max_length)\n",
    "            decoder_sequences, self.decoder_tokenizer = self.tokenize(train_target, max_length)\n",
    "            \n",
    "            # The buffer size must be equal or bigger than the total number of sentence pairs in the dataset\n",
    "            BUFFER_SIZE = len(train_input)\n",
    "\n",
    "            train_dataset = tf.data.Dataset.from_tensor_slices((encoder_sequences, decoder_sequences))\n",
    "            train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)\n",
    "\n",
    "            return train_dataset, self.encoder_tokenizer, self.decoder_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71007686-e9dd-48d6-b4b2-9b83886cf419",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d09e1ae6-980d-4f23-a7cb-dd6d3ba77a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 80\n",
    "BATCH_SIZE = 16\n",
    "EMBEDDING_DIM = 128\n",
    "UNITS = 256\n",
    "NUM_EXAMPLES = None # None -> consider the whole dataset\n",
    "MAX_LENGTH = 20 # None -> consider the whole length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1c0815-c02d-4148-87d9-b09adef82bdd",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7589ae9-aaf0-428c-884b-b5fa38699391",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = NMT_Parallel_Corpus(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0519dafe-9d04-4d25-8217-2c0b1423cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, tok_enc, tok_dec = corpus.create_datasets(BATCH_SIZE, NUM_EXAMPLES, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3323065-88cb-42e1-84b4-e4234e550fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus size: 198\n",
      "Selected corpus size: 198\n"
     ]
    }
   ],
   "source": [
    "print(f'Total corpus size: {corpus.total_size}')\n",
    "print(f'Selected corpus size: {corpus.selection_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f45307e5-b9b1-47b5-ac5a-9054f1d71919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 901 unique input tokens.\n",
      "Found 780 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "# Get the word to index mapping for input language\n",
    "word2idx_inputs = tok_enc.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
    "\n",
    "# Get the word to index mapping for output language\n",
    "word2idx_outputs = tok_dec.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "# Map indexes back into real words so we can view the results\n",
    "idx2word_inputs = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_outputs = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "360faa69-91cb-44b0-9f35-45c02da60bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab_size = len(tok_enc.word_index) + 1\n",
    "target_vocab_size = len(tok_dec.word_index) + 1\n",
    "max_length_input = list(train_dataset.as_numpy_iterator())[0][0].shape[1]\n",
    "max_length_target = list(train_dataset.as_numpy_iterator())[0][1].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c5470-1b9b-4855-9f7b-670f9a3aaa17",
   "metadata": {},
   "source": [
    "# Model Architechture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348b47f8-c217-41c7-b3bf-0a23b4f16a4e",
   "metadata": {},
   "source": [
    "## Bidirectional Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23a7d845-7745-42c0-b6f3-3728bb213912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, encoder_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_units = encoder_units\n",
    "        \n",
    "        # The Embedding layer convets token IDs to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM layer processes those vectors sequentially\n",
    "        self.lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.encoder_units,\n",
    "                                                                       return_sequences = True,\n",
    "                                                                       return_state = True,\n",
    "                                                                       recurrent_initializer = 'glorot_uniform'))\n",
    "    \n",
    "    def call(self, tokens, hidden_state = None):\n",
    "        \n",
    "        # The Embedding layer looks up the embedding for each token\n",
    "        embedding_vector = self.embedding(tokens)\n",
    "        \n",
    "        # None as default causes creation of zero-filled initial state tensors\n",
    "        all_h, fwd_h, fwd_c, bwd_h, bwd_c = self.lstm(embedding_vector, initial_state = hidden_state)\n",
    "        \n",
    "        # Returns the new sequence and its state\n",
    "        return all_h, fwd_h, fwd_c, bwd_h, bwd_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1da6b11-c587-45e7-8d01-e2acf2caeb52",
   "metadata": {},
   "source": [
    "## Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d541e68a-35ec-4fcd-bfdf-1c9fbfc61e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "\n",
    "    def call(self, query, value, mask):\n",
    "\n",
    "        w1_query = self.W1(query)\n",
    "        w2_key = self.W2(value)\n",
    "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
    "        value_mask = mask\n",
    "\n",
    "        context_vector, attention_weights = self.attention(inputs = [w1_query, value, w2_key],\n",
    "                                                           mask = [query_mask, value_mask],\n",
    "                                                           return_attention_scores = True)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7597b9f1-0bd6-499f-9ad6-209448340d84",
   "metadata": {},
   "source": [
    "## Bidirectional Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfa46a55-b005-47f4-8d3a-4c619fc76a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, target_vocab_size, embedding_dim, decoder_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoder_units = decoder_units\n",
    "    \n",
    "        # The Embedding layer convets token IDs to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, embedding_dim)\n",
    "        \n",
    "        # The LSTM keeps track of what's been generated so far\n",
    "        self.lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.decoder_units,\n",
    "                                                  return_sequences=True,\n",
    "                                                  return_state=True,\n",
    "                                                  recurrent_initializer='glorot_uniform'))\n",
    "        \n",
    "        # The RNN output will be the query for the attention layer.\n",
    "        self.attention = BahdanauAttention(self.decoder_units*2)\n",
    "\n",
    "        # Used to convert context vector to attention vector\n",
    "        self.Wc = tf.keras.layers.Dense(self.decoder_units*2, \n",
    "                                        activation = tf.math.tanh,\n",
    "                                        use_bias = False)\n",
    "        \n",
    "        # Final Dense layer on which softmax will be applied\n",
    "        self.dense = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, tokens, encoder_output, mask, initial_state = None):\n",
    "        \n",
    "        # Lookup the embeddings\n",
    "        embedding_vector = self.embedding(tokens)\n",
    "        \n",
    "        # Process one step with the LSTM\n",
    "        all_h, fwd_h, fwd_c, bwd_h, bwd_c = self.lstm(embedding_vector, initial_state = initial_state)\n",
    "        \n",
    "        # Use the RNN output as the query for the attention over the encoder output\n",
    "        context_vector, attention_weights = self.attention(query = all_h, \n",
    "                                                           value = encoder_output, \n",
    "                                                           mask = mask)\n",
    "  \n",
    "        # Concatenate the context_vector and rnn_output\n",
    "        # [ct; ht] shape: (batch t, value_units + query_units)\n",
    "        context_and_rnn_output = tf.concat([context_vector, all_h], axis=-1)\n",
    "\n",
    "        # Calculate attention vector\n",
    "        attention_vector = self.Wc(context_and_rnn_output)\n",
    "  \n",
    "        # Generate logit predictions\n",
    "        logits = self.dense(attention_vector)\n",
    "        \n",
    "        return logits, attention_weights, [fwd_h, fwd_c, bwd_h, bwd_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3afb891-c87c-4706-b961-109b8d5a34cc",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c39a93e7-027b-42d6-a070-8845d30d8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'auto')\n",
    "    mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1\n",
    "    mask = tf.cast(mask, dtype=tf.int64)  \n",
    "    loss = cross_entropy(y_true=real, y_pred=pred, sample_weight = mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22012b94-d9c1-4e08-999d-c04ff154d980",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14205fd5-b8e5-4a0d-9902-d0a0f35924cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 3.0920\n",
      "Time taken for 1 epoch 16.6301007270813 [s]\n",
      "\n",
      "Epoch 2 Loss 2.6221\n",
      "Time taken for 1 epoch 17.09188199043274 [s]\n",
      "\n",
      "Epoch 3 Loss 2.3742\n",
      "Time taken for 1 epoch 16.469273567199707 [s]\n",
      "\n",
      "Epoch 4 Loss 2.1812\n",
      "Time taken for 1 epoch 16.955027103424072 [s]\n",
      "\n",
      "Epoch 5 Loss 1.9421\n",
      "Time taken for 1 epoch 16.243409395217896 [s]\n",
      "\n",
      "Epoch 6 Loss 1.7448\n",
      "Time taken for 1 epoch 16.268481016159058 [s]\n",
      "\n",
      "Epoch 7 Loss 1.5023\n",
      "Time taken for 1 epoch 16.001455307006836 [s]\n",
      "\n",
      "Epoch 8 Loss 1.2781\n",
      "Time taken for 1 epoch 15.780846357345581 [s]\n",
      "\n",
      "Epoch 9 Loss 1.0792\n",
      "Time taken for 1 epoch 16.50383496284485 [s]\n",
      "\n",
      "Epoch 10 Loss 0.8566\n",
      "Time taken for 1 epoch 15.011319637298584 [s]\n",
      "\n",
      "Epoch 11 Loss 0.6891\n",
      "Time taken for 1 epoch 15.495977640151978 [s]\n",
      "\n",
      "Epoch 12 Loss 0.5551\n",
      "Time taken for 1 epoch 16.659340858459473 [s]\n",
      "\n",
      "Epoch 13 Loss 0.4293\n",
      "Time taken for 1 epoch 16.62898349761963 [s]\n",
      "\n",
      "Epoch 14 Loss 0.3244\n",
      "Time taken for 1 epoch 14.54774022102356 [s]\n",
      "\n",
      "Epoch 15 Loss 0.2372\n",
      "Time taken for 1 epoch 16.478387355804443 [s]\n",
      "\n",
      "Epoch 16 Loss 0.1730\n",
      "Time taken for 1 epoch 16.831201553344727 [s]\n",
      "\n",
      "Epoch 17 Loss 0.1215\n",
      "Time taken for 1 epoch 15.968270063400269 [s]\n",
      "\n",
      "Epoch 18 Loss 0.0855\n",
      "Time taken for 1 epoch 15.260737895965576 [s]\n",
      "\n",
      "Epoch 19 Loss 0.0604\n",
      "Time taken for 1 epoch 15.833021640777588 [s]\n",
      "\n",
      "Epoch 20 Loss 0.0439\n",
      "Time taken for 1 epoch 16.43934416770935 [s]\n",
      "\n",
      "Epoch 21 Loss 0.0329\n",
      "Time taken for 1 epoch 16.34880256652832 [s]\n",
      "\n",
      "Epoch 22 Loss 0.0253\n",
      "Time taken for 1 epoch 15.764373064041138 [s]\n",
      "\n",
      "Epoch 23 Loss 0.0206\n",
      "Time taken for 1 epoch 16.15191125869751 [s]\n",
      "\n",
      "Epoch 24 Loss 0.0186\n",
      "Time taken for 1 epoch 15.711489915847778 [s]\n",
      "\n",
      "Epoch 25 Loss 0.0161\n",
      "Time taken for 1 epoch 17.019266605377197 [s]\n",
      "\n",
      "Epoch 26 Loss 0.0139\n",
      "Time taken for 1 epoch 16.900736093521118 [s]\n",
      "\n",
      "Epoch 27 Loss 0.0128\n",
      "Time taken for 1 epoch 16.155542612075806 [s]\n",
      "\n",
      "Epoch 28 Loss 0.0113\n",
      "Time taken for 1 epoch 15.695643663406372 [s]\n",
      "\n",
      "Epoch 29 Loss 0.0108\n",
      "Time taken for 1 epoch 15.80594253540039 [s]\n",
      "\n",
      "Epoch 30 Loss 0.0097\n",
      "Time taken for 1 epoch 16.36013174057007 [s]\n",
      "\n",
      "Epoch 31 Loss 0.0090\n",
      "Time taken for 1 epoch 16.4525465965271 [s]\n",
      "\n",
      "Epoch 32 Loss 0.0083\n",
      "Time taken for 1 epoch 17.633273124694824 [s]\n",
      "\n",
      "Epoch 33 Loss 0.0078\n",
      "Time taken for 1 epoch 16.855876445770264 [s]\n",
      "\n",
      "Epoch 34 Loss 0.0074\n",
      "Time taken for 1 epoch 16.013165950775146 [s]\n",
      "\n",
      "Epoch 35 Loss 0.0072\n",
      "Time taken for 1 epoch 16.815181016921997 [s]\n",
      "\n",
      "Epoch 36 Loss 0.0068\n",
      "Time taken for 1 epoch 16.725727081298828 [s]\n",
      "\n",
      "Epoch 37 Loss 0.0067\n",
      "Time taken for 1 epoch 16.92596435546875 [s]\n",
      "\n",
      "Epoch 38 Loss 0.0061\n",
      "Time taken for 1 epoch 16.452953577041626 [s]\n",
      "\n",
      "Epoch 39 Loss 0.0059\n",
      "Time taken for 1 epoch 17.058746099472046 [s]\n",
      "\n",
      "Epoch 40 Loss 0.0056\n",
      "Time taken for 1 epoch 16.623381853103638 [s]\n",
      "\n",
      "Epoch 41 Loss 0.0056\n",
      "Time taken for 1 epoch 16.60641646385193 [s]\n",
      "\n",
      "Epoch 42 Loss 0.0052\n",
      "Time taken for 1 epoch 16.852200746536255 [s]\n",
      "\n",
      "Epoch 43 Loss 0.0053\n",
      "Time taken for 1 epoch 16.91814374923706 [s]\n",
      "\n",
      "Epoch 44 Loss 0.0048\n",
      "Time taken for 1 epoch 17.44565749168396 [s]\n",
      "\n",
      "Epoch 45 Loss 0.0047\n",
      "Time taken for 1 epoch 17.099666357040405 [s]\n",
      "\n",
      "Epoch 46 Loss 0.0046\n",
      "Time taken for 1 epoch 16.561412572860718 [s]\n",
      "\n",
      "Epoch 47 Loss 0.0045\n",
      "Time taken for 1 epoch 16.57057213783264 [s]\n",
      "\n",
      "Epoch 48 Loss 0.0043\n",
      "Time taken for 1 epoch 17.284509897232056 [s]\n",
      "\n",
      "Epoch 49 Loss 0.0043\n",
      "Time taken for 1 epoch 17.126140832901 [s]\n",
      "\n",
      "Epoch 50 Loss 0.0043\n",
      "Time taken for 1 epoch 17.14463496208191 [s]\n",
      "\n",
      "Epoch 51 Loss 0.0038\n",
      "Time taken for 1 epoch 16.492222547531128 [s]\n",
      "\n",
      "Epoch 52 Loss 0.0042\n",
      "Time taken for 1 epoch 16.69901156425476 [s]\n",
      "\n",
      "Epoch 53 Loss 0.0038\n",
      "Time taken for 1 epoch 16.600290536880493 [s]\n",
      "\n",
      "Epoch 54 Loss 0.0037\n",
      "Time taken for 1 epoch 16.80397367477417 [s]\n",
      "\n",
      "Epoch 55 Loss 0.0037\n",
      "Time taken for 1 epoch 16.12610626220703 [s]\n",
      "\n",
      "Epoch 56 Loss 0.0035\n",
      "Time taken for 1 epoch 16.637036085128784 [s]\n",
      "\n",
      "Epoch 57 Loss 0.0034\n",
      "Time taken for 1 epoch 17.372336387634277 [s]\n",
      "\n",
      "Epoch 58 Loss 0.0034\n",
      "Time taken for 1 epoch 17.05144691467285 [s]\n",
      "\n",
      "Epoch 59 Loss 0.0034\n",
      "Time taken for 1 epoch 16.83088970184326 [s]\n",
      "\n",
      "Epoch 60 Loss 0.0034\n",
      "Time taken for 1 epoch 16.685405254364014 [s]\n",
      "\n",
      "Epoch 61 Loss 0.0032\n",
      "Time taken for 1 epoch 17.115320920944214 [s]\n",
      "\n",
      "Epoch 62 Loss 0.0032\n",
      "Time taken for 1 epoch 16.927836894989014 [s]\n",
      "\n",
      "Epoch 63 Loss 0.0031\n",
      "Time taken for 1 epoch 17.061460494995117 [s]\n",
      "\n",
      "Epoch 64 Loss 0.0031\n",
      "Time taken for 1 epoch 16.02722144126892 [s]\n",
      "\n",
      "Epoch 65 Loss 0.0029\n",
      "Time taken for 1 epoch 17.269994974136353 [s]\n",
      "\n",
      "Epoch 66 Loss 0.0030\n",
      "Time taken for 1 epoch 17.172447443008423 [s]\n",
      "\n",
      "Epoch 67 Loss 0.0029\n",
      "Time taken for 1 epoch 16.921852588653564 [s]\n",
      "\n",
      "Epoch 68 Loss 0.0029\n",
      "Time taken for 1 epoch 17.158321857452393 [s]\n",
      "\n",
      "Epoch 69 Loss 0.0028\n",
      "Time taken for 1 epoch 16.863550901412964 [s]\n",
      "\n",
      "Epoch 70 Loss 0.0029\n",
      "Time taken for 1 epoch 16.8901789188385 [s]\n",
      "\n",
      "Epoch 71 Loss 0.0027\n",
      "Time taken for 1 epoch 17.11533284187317 [s]\n",
      "\n",
      "Epoch 72 Loss 0.0026\n",
      "Time taken for 1 epoch 17.18824052810669 [s]\n",
      "\n",
      "Epoch 73 Loss 0.0026\n",
      "Time taken for 1 epoch 17.292386293411255 [s]\n",
      "\n",
      "Epoch 74 Loss 0.0026\n",
      "Time taken for 1 epoch 17.434962511062622 [s]\n",
      "\n",
      "Epoch 75 Loss 0.0025\n",
      "Time taken for 1 epoch 16.664257287979126 [s]\n",
      "\n",
      "Epoch 76 Loss 0.0025\n",
      "Time taken for 1 epoch 16.572243213653564 [s]\n",
      "\n",
      "Epoch 77 Loss 0.0026\n",
      "Time taken for 1 epoch 16.84277367591858 [s]\n",
      "\n",
      "Epoch 78 Loss 0.0024\n",
      "Time taken for 1 epoch 16.771492958068848 [s]\n",
      "\n",
      "Epoch 79 Loss 0.0025\n",
      "Time taken for 1 epoch 17.114988803863525 [s]\n",
      "\n",
      "Epoch 80 Loss 0.0024\n",
      "Time taken for 1 epoch 17.364230155944824 [s]\n",
      "\n",
      "Total training time: 22.154540308316548 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(input_vocab_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\n",
    "decoder = Decoder(target_vocab_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.005, beta_1 = 0.9, beta_2 = 0.999, decay = 0.01)\n",
    "loss_history = []\n",
    "\n",
    "# Create a checkpoint object to save the model\n",
    "checkpoint_dir = './training_ckpt_seq2seq'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(train_dataset):\n",
    "        \n",
    "        # Convert IDs to masks.\n",
    "        input_mask = inp != 0\n",
    "        target_mask = targ != 0\n",
    "        \n",
    "        loss = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            enc_output, enc_fwd_h, enc_fwd_c, enc_bwd_h, enc_bwd_c = encoder(inp)\n",
    "            #dec_state = [enc_fwd_h, enc_fwd_c, enc_bwd_h, enc_bwd_c]\n",
    "            dec_state = [enc_bwd_h, enc_bwd_c, enc_fwd_h, enc_fwd_c]  # Encoder outputs are reversed (Sabahi et al., 2018)\n",
    "            dec_input = tf.expand_dims([word2idx_outputs['<sos>']] * BATCH_SIZE, 1)\n",
    "            \n",
    "            for t in range(1, targ.shape[1]):\n",
    "                \n",
    "                # passing enc_output to the decoder\n",
    "                logits, attention_weights, dec_state = decoder(dec_input, enc_output, input_mask, dec_state)\n",
    "                \n",
    "                # Calculate cumulative loss\n",
    "                loss += loss_function(targ[:, t], logits)\n",
    "                \n",
    "                # Apply teacher forcing:  feeding the target as the next input\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "            \n",
    "        total_loss += (loss / int(targ.shape[1]))\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "    loss_history.append(total_loss / len(train_dataset))\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / len(train_dataset)))\n",
    "    print('Time taken for 1 epoch {} [s]\\n'.format(time.time() - start))\n",
    "print(f'Total training time: {(time.time() - start_time)/60} minutes\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c070680-3835-4f1d-bfa1-87d3bae7a882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, tight_layout = True, figsize = (6, 4))\n",
    "plt.plot(loss_history)\n",
    "plt.legend(['Training'])\n",
    "plt.title(CORPUS_NAME + ' Corpus')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "if MAX_LENGTH == None:\n",
    "    length = 'max'\n",
    "else:\n",
    "    length = str(MAX_LENGTH)\n",
    "\n",
    "fig.savefig('./images/' + CORPUS_NAME + '_loss_len_' + length + '_rnn3.png', format = 'png')\n",
    "#fig.savefig('/content/drive/MyDrive/Spanish-Tarahumara-Translator/images/' + CORPUS_NAME + '_loss_len_' + length + '_rnn3.png', format = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5376bd-c032-46f8-aef2-992c7fedc76c",
   "metadata": {},
   "source": [
    "# Prediction Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2f44da8-468d-4d19-848c-98925df0a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_text, encoder, decoder, input_max_len, output_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs):\n",
    "    if input_text is None:\n",
    "        input_text = input_data[np.random.choice(len(input_data))]\n",
    "    \n",
    "    # Tokenize the input sequence\n",
    "    input_seq = tokenizer_inputs.texts_to_sequences([input_text])\n",
    "    \n",
    "    # Pad the sentence\n",
    "    input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=input_max_len, padding='post')\n",
    "    \n",
    "    # Consider only unpadded part of the sequence\n",
    "    input_mask = input_seq != 0\n",
    "    \n",
    "    # Generate encoder output\n",
    "    en_outputs = encoder(tf.constant(input_seq))\n",
    "    \n",
    "    # Create the decoder input (<SOS> token)\n",
    "    de_input = tf.constant([[word2idx_outputs['<sos>']]])\n",
    "    \n",
    "    # Set the decoder states to the encoder vector or encoder hidden state\n",
    "    dec_state = en_outputs[1:]\n",
    "    #dec_state = [en_outputs[3], en_outputs[4], en_outputs[1], en_outputs[2]]\n",
    "    \n",
    "    out_words = []\n",
    "    while True:\n",
    "        # Decode and get the output probabilities\n",
    "        de_output, _, dec_state = decoder(de_input, en_outputs[0], input_mask, dec_state)\n",
    "        \n",
    "        # Select the word with the highest probability\n",
    "        de_input = tf.argmax(de_output, -1)\n",
    "        \n",
    "        # Append the word to the predicted output\n",
    "        out_words.append(idx2word_outputs[de_input.numpy()[0][0]])\n",
    "        \n",
    "        # Finish when <EOS> token is found or the max length is reached\n",
    "        if out_words[-1] == '<eos>' or len(out_words) >= output_max_len:\n",
    "            break\n",
    "\n",
    "    translation = ' '.join(out_words)\n",
    "    return translation, out_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa1f32e-03ce-4fea-a051-0f4f606434fb",
   "metadata": {},
   "source": [
    "## Evaluating Predictions with Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be7b1ae6-9d1a-4685-8cc4-18689541518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = corpus.train_set['Source'].apply(lambda x : predict(x, encoder, decoder, max_length_input, max_length_target, tok_enc, word2idx_outputs, idx2word_outputs)[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60ac29ea-3d83-46d6-9ec3-bfeb9471cc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>BLEU-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; ¿ dónde vive usted ? &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; ¿ comi bité mujé ? &lt;EOS&gt;</td>\n",
       "      <td>comi comi bité mujé ? &lt;eos&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.221339e-77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; a lo que canta un pájaro . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; mapu a'lí ta nalépua chulukí jíti . &lt;EOS&gt;</td>\n",
       "      <td>a'lí mapu a'lí ta nalépua chulukí jíti . &lt;eos&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.623413e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; está haciendo mucho frío . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; hue ruluá . &lt;EOS&gt;</td>\n",
       "      <td>ruluá &lt;eos&gt;</td>\n",
       "      <td>0.367879</td>\n",
       "      <td>6.702145e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; tus abuelos maternos . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; kému apalócha a'lí kému u'sú . &lt;EOS&gt;</td>\n",
       "      <td>ga'lá semáti semáti aní . &lt;eos&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; el tarahumar con el sonido de la piel despierta a sus padres &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; ralámuli wichí anéala kiti busurébi e'wénuala &lt;EOS&gt;</td>\n",
       "      <td>ralámuli wichí anéala kíti busulébi we'é &lt;eos&gt;</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.775354e-78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     Source  \\\n",
       "0                                          <SOS> ¿ dónde vive usted ? <EOS>   \n",
       "1                                    <SOS> a lo que canta un pájaro . <EOS>   \n",
       "2                                    <SOS> está haciendo mucho frío . <EOS>   \n",
       "3                                        <SOS> tus abuelos maternos . <EOS>   \n",
       "4  <SOS> el tarahumar con el sonido de la piel despierta a sus padres <EOS>   \n",
       "\n",
       "                                                      Target  \\\n",
       "0                             <SOS> ¿ comi bité mujé ? <EOS>   \n",
       "1            <SOS> mapu a'lí ta nalépua chulukí jíti . <EOS>   \n",
       "2                                    <SOS> hue ruluá . <EOS>   \n",
       "3                 <SOS> kému apalócha a'lí kému u'sú . <EOS>   \n",
       "4  <SOS> ralámuli wichí anéala kiti busurébi e'wénuala <EOS>   \n",
       "\n",
       "                                      Predictions    BLEU-1         BLEU-4  \n",
       "0                     comi comi bité mujé ? <eos>  1.000000   1.221339e-77  \n",
       "1  a'lí mapu a'lí ta nalépua chulukí jíti . <eos>  1.000000   5.623413e-01  \n",
       "2                                     ruluá <eos>  0.367879  6.702145e-232  \n",
       "3                 ga'lá semáti semáti aní . <eos>  0.000000   0.000000e+00  \n",
       "4  ralámuli wichí anéala kíti busulébi we'é <eos>  0.500000   5.775354e-78  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "train_df = corpus.train_set\n",
    "train_df['Predictions'] = predictions\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf565a-b356-48ee-8c60-0c100e6c1e2e",
   "metadata": {},
   "source": [
    "### BLEU Scores Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "73ea9fbe-efa0-449a-83ab-26844100cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_bleu = corpus.train_set['Source'].apply(lambda x : predict(x,encoder, decoder, max_length_input, max_length_target, tok_enc, word2idx_outputs, idx2word_outputs)[1]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb642f0-1400-4a3c-b5d3-8dca08d58d3c",
   "metadata": {},
   "source": [
    "#### Translation and Target Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "175b7f82-5274-4cda-ab71-2a5b1e30dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction output preprocessing for calculating BLEU score\n",
    "for i in range(len(candidates_bleu)):\n",
    "    # Remove duplicate elements like commas\n",
    "    candidates_bleu[i] = list(dict.fromkeys(candidates_bleu[i]))\n",
    "    # Remove <EOS> token\n",
    "    if '<eos>' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('<eos>')\n",
    "    # Remove special punctuation characters\n",
    "    if '.' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('.')\n",
    "    if ',' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove(',')\n",
    "    if '!' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('!')\n",
    "    if '¡' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('¡')\n",
    "    if '?' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('?')\n",
    "    if '¿' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('¿')\n",
    "\n",
    "# Target preprocessing for calculating BLEU score\n",
    "references_bleu = train_df['Target'].to_list()\n",
    "\n",
    "for i in range(len(references_bleu)):\n",
    "    references_bleu[i] = references_bleu[i].split()\n",
    "    # Remove duplicate elements like commas\n",
    "    references_bleu[i] = list(dict.fromkeys(references_bleu[i]))\n",
    "    # Remove <SOS> token\n",
    "    references_bleu[i].remove('<SOS>')\n",
    "    # Remove <EOS> token\n",
    "    references_bleu[i].remove('<EOS>')\n",
    "    # Remove special punctuation characters\n",
    "    if '.' in references_bleu[i]:\n",
    "        references_bleu[i].remove('.')\n",
    "    if ',' in references_bleu[i]:\n",
    "        references_bleu[i].remove(',')\n",
    "    if '!' in references_bleu[i]:\n",
    "        references_bleu[i].remove('!')\n",
    "    if '¡' in references_bleu[i]:\n",
    "        references_bleu[i].remove('¡')\n",
    "    if '?' in references_bleu[i]:\n",
    "        references_bleu[i].remove('?')\n",
    "    if '¿' in references_bleu[i]:\n",
    "        references_bleu[i].remove('¿')\n",
    "        \n",
    "references_bleu_train = list()\n",
    "for i in range(len(references_bleu)):\n",
    "    references_bleu_train.append(list())\n",
    "    references_bleu_train[i].append(references_bleu[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9f90c-3919-4214-bf5b-ffa4e22a162d",
   "metadata": {},
   "source": [
    "* **Corpus BLEU Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c283120-e0d5-49f4-b1c5-f18fcab8c8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU-1 score: 0.36268133326091556\n",
      "Corpus BLEU-4 score: 0.20560711482368899\n"
     ]
    }
   ],
   "source": [
    "score = corpus_bleu(references_bleu_train, candidates_bleu, weights = (1,0,0,0))\n",
    "print(f'Corpus BLEU-1 score: {score}')\n",
    "score = corpus_bleu(references_bleu_train, candidates_bleu)\n",
    "print(f'Corpus BLEU-4 score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd3462-d51e-49a6-b27c-b4c78f26df02",
   "metadata": {},
   "source": [
    "* **Sentence BLEU Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39984968-f2ff-4fd7-a5f9-f116b86f1854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>BLEU-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; ¿ dónde vive usted ? &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; ¿ comi bité mujé ? &lt;EOS&gt;</td>\n",
       "      <td>comi comi bité mujé ? &lt;eos&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.221339e-77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; a lo que canta un pájaro . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; mapu a'lí ta nalépua chulukí jíti . &lt;EOS&gt;</td>\n",
       "      <td>a'lí mapu a'lí ta nalépua chulukí jíti . &lt;eos&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.623413e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; está haciendo mucho frío . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; hue ruluá . &lt;EOS&gt;</td>\n",
       "      <td>ruluá &lt;eos&gt;</td>\n",
       "      <td>0.367879</td>\n",
       "      <td>6.702145e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; tus abuelos maternos . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; kému apalócha a'lí kému u'sú . &lt;EOS&gt;</td>\n",
       "      <td>ga'lá semáti semáti aní . &lt;eos&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; el tarahumar con el sonido de la piel despierta a sus padres &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; ralámuli wichí anéala kiti busurébi e'wénuala &lt;EOS&gt;</td>\n",
       "      <td>ralámuli wichí anéala kíti busulébi we'é &lt;eos&gt;</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.775354e-78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     Source  \\\n",
       "0                                          <SOS> ¿ dónde vive usted ? <EOS>   \n",
       "1                                    <SOS> a lo que canta un pájaro . <EOS>   \n",
       "2                                    <SOS> está haciendo mucho frío . <EOS>   \n",
       "3                                        <SOS> tus abuelos maternos . <EOS>   \n",
       "4  <SOS> el tarahumar con el sonido de la piel despierta a sus padres <EOS>   \n",
       "\n",
       "                                                      Target  \\\n",
       "0                             <SOS> ¿ comi bité mujé ? <EOS>   \n",
       "1            <SOS> mapu a'lí ta nalépua chulukí jíti . <EOS>   \n",
       "2                                    <SOS> hue ruluá . <EOS>   \n",
       "3                 <SOS> kému apalócha a'lí kému u'sú . <EOS>   \n",
       "4  <SOS> ralámuli wichí anéala kiti busurébi e'wénuala <EOS>   \n",
       "\n",
       "                                      Predictions    BLEU-1         BLEU-4  \n",
       "0                     comi comi bité mujé ? <eos>  1.000000   1.221339e-77  \n",
       "1  a'lí mapu a'lí ta nalépua chulukí jíti . <eos>  1.000000   5.623413e-01  \n",
       "2                                     ruluá <eos>  0.367879  6.702145e-232  \n",
       "3                 ga'lá semáti semáti aní . <eos>  0.000000   0.000000e+00  \n",
       "4  ralámuli wichí anéala kíti busulébi we'é <eos>  0.500000   5.775354e-78  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu_scores = []\n",
    "for i in range(len(references_bleu)):\n",
    "    sentence_bleu_scores.append(sentence_bleu(references_bleu_train[i], candidates_bleu[i], weights = (1,0,0,0)))\n",
    "train_df['BLEU-1'] = sentence_bleu_scores\n",
    "\n",
    "sentence_bleu_scores = []\n",
    "for i in range(len(references_bleu)):\n",
    "    sentence_bleu_scores.append(sentence_bleu(references_bleu_train[i], candidates_bleu[i])) \n",
    "train_df['BLEU-4'] = sentence_bleu_scores\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a1ad443f-6ae9-498f-b4b3-56f49f613a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_excel('./results/train_' + CORPUS_NAME + '_len_' + length + '_rnn3.xlsx')\n",
    "#train_df.to_excel('/content/drive/MyDrive/Spanish-Tarahumara-Translator/results/train_' + CORPUS_NAME + '_len_' + length + '_rnn3.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265bac8-e124-4839-a281-2849483215bc",
   "metadata": {},
   "source": [
    "## Predictions with Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6ebd2d3-d17c-49b9-81f9-575e7571d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = corpus.validation_set['Source'].apply(lambda x : predict(x, encoder, decoder, max_length_input, max_length_target, tok_enc, word2idx_outputs, idx2word_outputs)[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa1163f8-b2ae-49a0-86e3-e3b3f0999e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>BLEU-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; artículo 2o . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; osirúa'mi 2 . &lt;EOS&gt;</td>\n",
       "      <td>5 . &lt;eos&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; ya haz nacer al maíz y a las demás plantas . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; má ochébi suunú a'lí jalé chó reyawi . &lt;EOS&gt;</td>\n",
       "      <td>ralámuli wichí anéala kiti busurébi e'wénuala &lt;eos&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; para que comience a nacer la hierba &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; mapuliká reyáwi chotáma a'wiyá &lt;EOS&gt;</td>\n",
       "      <td>muchiga cábasi . &lt;eos&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; despiertan alegres al escuchar el eco . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; népi busuré kaníla kipúu rampóli kebáala . &lt;EOS&gt;</td>\n",
       "      <td>ba'wéchi . &lt;eos&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; fue así como fueron creados los rarámuri y los chabochi &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; echiriká iwítali rarámuri alí chabochi &lt;EOS&gt;</td>\n",
       "      <td>najítila chi , busulé , mapu eyé we'é ! &lt;eos&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Source  \\\n",
       "0                                            <SOS> artículo 2o . <EOS>   \n",
       "1             <SOS> ya haz nacer al maíz y a las demás plantas . <EOS>   \n",
       "2                      <SOS> para que comience a nacer la hierba <EOS>   \n",
       "3                  <SOS> despiertan alegres al escuchar el eco . <EOS>   \n",
       "4  <SOS> fue así como fueron creados los rarámuri y los chabochi <EOS>   \n",
       "\n",
       "                                                   Target  \\\n",
       "0                               <SOS> osirúa'mi 2 . <EOS>   \n",
       "1      <SOS> má ochébi suunú a'lí jalé chó reyawi . <EOS>   \n",
       "2              <SOS> mapuliká reyáwi chotáma a'wiyá <EOS>   \n",
       "3  <SOS> népi busuré kaníla kipúu rampóli kebáala . <EOS>   \n",
       "4      <SOS> echiriká iwítali rarámuri alí chabochi <EOS>   \n",
       "\n",
       "                                           Predictions  BLEU-1  BLEU-4  \n",
       "0                                            5 . <eos>     0.0     0.0  \n",
       "1  ralámuli wichí anéala kiti busurébi e'wénuala <eos>     0.0     0.0  \n",
       "2                               muchiga cábasi . <eos>     0.0     0.0  \n",
       "3                                     ba'wéchi . <eos>     0.0     0.0  \n",
       "4        najítila chi , busulé , mapu eyé we'é ! <eos>     0.0     0.0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = corpus.validation_set\n",
    "validation_df['Predictions'] = predictions\n",
    "validation_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cef71f-6262-4d7e-997d-d61a64747c7b",
   "metadata": {},
   "source": [
    "### BLEU Score (Validation Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0dc63c2e-16ec-4be2-8fdf-a5a6e02bae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_bleu = corpus.validation_set['Source'].apply(lambda x : predict(x, encoder, decoder, max_length_input, max_length_target, tok_enc, word2idx_outputs, idx2word_outputs)[1]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdfbf44-ed23-4151-b38d-601eed912150",
   "metadata": {},
   "source": [
    "#### Translation and Target Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20da5ab8-2e01-4e9a-aab1-bcfe30c9ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction output preprocessing for calculating BLEU score\n",
    "for i in range(len(candidates_bleu)):\n",
    "    # Remove duplicate elements like commas\n",
    "    candidates_bleu[i] = list(dict.fromkeys(candidates_bleu[i]))\n",
    "    # Remove <EOS> token\n",
    "    if '<eos>' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('<eos>')\n",
    "    # Remove special punctuation characters\n",
    "    if '.' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('.')\n",
    "    if ',' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove(',')\n",
    "    if '!' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('!')\n",
    "    if '¡' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('¡')\n",
    "    if '?' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('?')\n",
    "    if '¿' in candidates_bleu[i]:\n",
    "        candidates_bleu[i].remove('¿')\n",
    "        \n",
    "# Target preprocessing for calculating BLEU score\n",
    "references_bleu = validation_df['Target'].to_list()\n",
    "\n",
    "for i in range(len(references_bleu)):\n",
    "    references_bleu[i] = references_bleu[i].split()\n",
    "    # Remove duplicate elements like commas\n",
    "    references_bleu[i] = list(dict.fromkeys(references_bleu[i]))\n",
    "    # Remove <SOS> token\n",
    "    references_bleu[i].remove('<SOS>')\n",
    "    # Remove <EOS> token\n",
    "    references_bleu[i].remove('<EOS>')\n",
    "    # Remove special punctuation characters\n",
    "    if '.' in references_bleu[i]:\n",
    "        references_bleu[i].remove('.')\n",
    "    if ',' in references_bleu[i]:\n",
    "        references_bleu[i].remove(',')\n",
    "    if '!' in references_bleu[i]:\n",
    "        references_bleu[i].remove('!')\n",
    "    if '¡' in references_bleu[i]:\n",
    "        references_bleu[i].remove('¡')\n",
    "    if '?' in references_bleu[i]:\n",
    "        references_bleu[i].remove('?')\n",
    "    if '¿' in references_bleu[i]:\n",
    "        references_bleu[i].remove('¿')\n",
    "        \n",
    "references_bleu_validation = list()\n",
    "for i in range(len(references_bleu)):\n",
    "    references_bleu_validation.append(list())\n",
    "    references_bleu_validation[i].append(references_bleu[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c13d1b-6493-4170-971b-b0944a299356",
   "metadata": {},
   "source": [
    "* **Corpus BLEU Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5cc68c81-2f5f-448a-96be-25de388d06be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU-1 score: 0.029955012332555212\n",
      "Corpus BLEU-4 score: 6.931318099669857e-156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "score = corpus_bleu(references_bleu_validation, candidates_bleu, weights = (1,0,0,0))\n",
    "print(f'Corpus BLEU-1 score: {score}')\n",
    "score = corpus_bleu(references_bleu_validation, candidates_bleu)\n",
    "print(f'Corpus BLEU-4 score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd36c6-6f2f-406a-8b6f-0b4a7b797e1f",
   "metadata": {},
   "source": [
    "* **Sentence BLEU Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ae07863-a2b2-413e-ba75-694f0a4a069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\envs\\SMT\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>BLEU-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; artículo 2o . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; osirúa'mi 2 . &lt;EOS&gt;</td>\n",
       "      <td>5 . &lt;eos&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; ya haz nacer al maíz y a las demás plantas . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; má ochébi suunú a'lí jalé chó reyawi . &lt;EOS&gt;</td>\n",
       "      <td>ralámuli wichí anéala kiti busurébi e'wénuala &lt;eos&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; para que comience a nacer la hierba &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; mapuliká reyáwi chotáma a'wiyá &lt;EOS&gt;</td>\n",
       "      <td>muchiga cábasi . &lt;eos&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; despiertan alegres al escuchar el eco . &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; népi busuré kaníla kipúu rampóli kebáala . &lt;EOS&gt;</td>\n",
       "      <td>ba'wéchi . &lt;eos&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; fue así como fueron creados los rarámuri y los chabochi &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; echiriká iwítali rarámuri alí chabochi &lt;EOS&gt;</td>\n",
       "      <td>najítila chi , busulé , mapu eyé we'é ! &lt;eos&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Source  \\\n",
       "0                                            <SOS> artículo 2o . <EOS>   \n",
       "1             <SOS> ya haz nacer al maíz y a las demás plantas . <EOS>   \n",
       "2                      <SOS> para que comience a nacer la hierba <EOS>   \n",
       "3                  <SOS> despiertan alegres al escuchar el eco . <EOS>   \n",
       "4  <SOS> fue así como fueron creados los rarámuri y los chabochi <EOS>   \n",
       "\n",
       "                                                   Target  \\\n",
       "0                               <SOS> osirúa'mi 2 . <EOS>   \n",
       "1      <SOS> má ochébi suunú a'lí jalé chó reyawi . <EOS>   \n",
       "2              <SOS> mapuliká reyáwi chotáma a'wiyá <EOS>   \n",
       "3  <SOS> népi busuré kaníla kipúu rampóli kebáala . <EOS>   \n",
       "4      <SOS> echiriká iwítali rarámuri alí chabochi <EOS>   \n",
       "\n",
       "                                           Predictions  BLEU-1  BLEU-4  \n",
       "0                                            5 . <eos>     0.0     0.0  \n",
       "1  ralámuli wichí anéala kiti busurébi e'wénuala <eos>     0.0     0.0  \n",
       "2                               muchiga cábasi . <eos>     0.0     0.0  \n",
       "3                                     ba'wéchi . <eos>     0.0     0.0  \n",
       "4        najítila chi , busulé , mapu eyé we'é ! <eos>     0.0     0.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu_scores = []\n",
    "for i in range(len(references_bleu)):\n",
    "    sentence_bleu_scores.append(sentence_bleu(references_bleu_validation[i], candidates_bleu[i], weights = (1,0,0,0)))\n",
    "validation_df['BLEU-1'] = sentence_bleu_scores\n",
    "\n",
    "sentence_bleu_scores = []\n",
    "for i in range(len(references_bleu)):\n",
    "    sentence_bleu_scores.append(sentence_bleu(references_bleu_validation[i], candidates_bleu[i]))\n",
    "validation_df['BLEU-4'] = sentence_bleu_scores\n",
    "validation_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a859f197-5c37-44f0-93fc-b2a56794cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.to_excel('./results/val_' + CORPUS_NAME + '_len_' + length + '_rnn3.xlsx')\n",
    "#validation_df.to_excel('/content/drive/MyDrive/Spanish-Tarahumara-Translator/results/val_' + CORPUS_NAME + '_len_' + length + '_rnn3.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682de9a-8deb-490b-9328-814d9bbcbd71",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<li><a href=\"https://aclanthology.org/D14-1179\">Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation</a> (Cho et al., EMNLP 2014)</li>\n",
    "\n",
    "<li><a href=\"https://arxiv.org/abs/1409.0473\">Neural Machine Translation by Jointly Learning to Align and Translate</a> (Bahdanau et al., ICLR 2015)</li>\n",
    "\n",
    "<li><a href=\"https://arxiv.org/abs/1809.06662\">Bidirectional Attentional Encoder-Decoder Model and Bidirectional Beam Search for Abstractive Summarization</a> (Al-Sabahi et al., arXiv 2018)</li>\n",
    "\n",
    "<li><a href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/nmt_with_attention.ipynb\">TensorFlow Tutorial:  Neural Machine Translation with Attention</a> (GitHub Repository)</li>\n",
    "\n",
    "<li><a href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb\">TensorFlow Tutorial:  Text Generation with an RNN</a> (GitHub Repository)</li>\n",
    "\n",
    "<li><a href=\"https://colab.research.google.com/github/tensorflow/addons/blob/master/docs/tutorials/networks_seq2seq_nmt.ipynb\">TensorFlow Addons Networks:  Sequence-to-Sequence NMT with Attention Mechanism</a> (GitHub Repository)</li>\n",
    "\n",
    "<li><a href=\"https://github.com/edumunozsala/NMT-encoder-decoder-Attention\">NMT-encoder-decoder-Attention</a> (GitHub Repository)</li>\n",
    "\n",
    "<li><a href=\"https://www.kaggle.com/code/rizdelhi/end-to-end-nlp-4-attention-and-transformer\">end-to-end-nlp-4-attention-and-transformer</a> (Kaggle Notebook)</li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMT",
   "language": "python",
   "name": "smt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
